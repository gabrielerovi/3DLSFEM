\documentclass[]{usiinfprospectus}
\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
%\geometry{landscape}                		% Activate for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{booktabs}
\usepackage {tikz}
\usetikzlibrary {positioning}
\definecolor {processblue}{cmyk}{0.96,0,0,0}

\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage{amsthm}
\usepackage{amsmath}
\captionsetup{labelfont={bf}}

\author{Gabriele Rovi}

\title{Stress-based Methods for variational inequalities in solid mechanics: }
\subtitle{FE discretization and solution by hierarchical optimization}
\versiondate{\today}

\begin{committee}
%With more than 1 advisor an error is raised...: only 1 advisor is allowed!
\researchadvisor[Universit\`a della Svizzera Italiana, Switzerland]{Prof.}{Rolf}{Krause}
\academicadvisor[Universit\`a della Svizzera Italiana, Switzerland]{Prof.}{Rolf}{Krause}
\committeemember[Universit\`a della Svizzera Italiana, Switzerland]{Prof.}{}{Luca Gambardella}
\committeemember[Universit\`a della Svizzera Italiana, Switzerland]{Prof.}{}{Silvia Santini}
%\committeemember[Universit\`a della Svizzera Italiana, Switzerland]{Prof.}{Committee}{Member3}
%\coadvisor[Universit\`a della Svizzera Italiana, Switzerland]{Prof.}{Research}{Co-Advisor1}
%\coadvisor[Universit\`a della Svizzera Italiana, Switzerland]{Prof.}{Research}{Co-Advisor2}
%\coadvisor[Universit\`a della Svizzera Italiana, Switzerland]{Prof.}{Research}{Co-Advisor3}
\phddirector{Prof.}{Binder}{/Bronstein}
\end{committee}

\abstract {
In many engineering applications, some of the most important quantities of interest are the forces. In particular the forces on a solid structure can be generated by the contact with another body. Possible examples of this phenomenon can be the contact of: a foundation with the soil; a biomedical prothesis with a portion of the human body;  the aortic valves, during their closure; and so on. \\
The aim of this project is modelling contact problems in solid mechanics so that a good approximation of the stresses (strictly related to the forces) is attained. For such a purpose, it is exploited  the huge potential of finite element approaches based on the approximation of stresses as the dual variable for variational inequalities. Approximating stresses directly by suitable finite element spaces allows for algorithmic simplifications and improved accuracy, in particular, in association with plasticity and friction where stress components play a prominent role. \\
Here the Least Square (LS) Finite Element Method (FEM) applied to contact linear elasticity is examined. Such approach is able to compute good approximation of stresses and deal with incompressible solids. The solution space is given by the pairs $H^1 \times H_{div}$ to which displacements and stresses respectively belong. Since the related system is ill-conditioned, fast solvers as multigrid are needed. Actually, at the state of the art, no fast solver for LS linear elasticity, much less for contact problems, has been developed. Such an extension is actually the goal of the present work.
%This includes models of frictional contact as well as elasto-plastic deformations and emphasizes adaptive refinement strategies based on built-in a posteriori error estimators as well as efficient iterative solution methods for the arising non-smooth problems. 
}

\newcommand{\supp}{\operatorname{supp}}
\newcommand{\dist}{\operatorname{dist}}
\newcommand{\divr}{\operatorname{div}}
\newcommand{\tdiv}{\operatorname{div}}
\newcommand{\ess}{\operatorname{ess}}
\newcommand{\rotore}{\operatorname{rot}}
\newcommand{\curl}{\operatorname{\textbf{curl}}}
\newcommand{\bcurl}{\operatorname{\textbf{curl}}}
\newcommand{\tr}{\operatorname{tr}}
\newcommand{\bA}{\textbf{A}}
\newcommand{\ba}{\textbf{a}}
\newcommand{\bb}{\textbf{b}}
\newcommand{\bB}{\textbf{B}}
\newcommand{\bc}{\textbf{c}}
\newcommand{\bC}{\textbf{C}}
\newcommand{\bd}{\textbf{d}}
\newcommand{\bD}{\textbf{D}}
\newcommand{\be}{\textbf{e}}
\newcommand{\bE}{\textbf{E}}
\newcommand{\bff}{\textbf{f}}
\newcommand{\bF}{\textbf{F}}
\newcommand{\bg}{\textbf{g}}
\newcommand{\bG}{\textbf{G}}
\newcommand{\bi}{\textbf{i}}
\newcommand{\bI}{\textbf{I}}
\newcommand{\bj}{\textbf{j}}
\newcommand{\bJ}{\textbf{J}}
\newcommand{\bh}{\textbf{h}}
\newcommand{\bH}{\textbf{H}}
\newcommand{\bk}{\textbf{k}}
\newcommand{\bK}{\textbf{K}}
\newcommand{\bl}{\textbf{l}}
\newcommand{\bL}{\textbf{L}}
\newcommand{\blambda}{\boldsymbol{\lambda}}
\newcommand{\bLambda}{\boldsymbol{\Lambda}}
\newcommand{\bm}{\textbf{m}}
\newcommand{\bM}{\textbf{M}}
\newcommand{\bn}{\textbf{n}}
\newcommand{\bN}{\textbf{N}}
\newcommand{\bp}{\textbf{p}}
\newcommand{\bP}{\textbf{P}}
\newcommand{\bpi}{\boldsymbol{\pi}}
\newcommand{\bPi}{\boldsymbol{\Pi}}
\newcommand{\bo}{\textbf{o}}
\newcommand{\bq}{\textbf{q}}
\newcommand{\bQ}{\textbf{Q}}
\newcommand{\br}{\textbf{r}}
\newcommand{\bR}{\textbf{R}}
\newcommand{\bs}{\textbf{s}}
\newcommand{\bS}{\textbf{S}}
\newcommand{\btau}{\boldsymbol{\tau}}
\newcommand{\bt}{\textbf{t}}
\newcommand{\bv}{\textbf{v}}
\newcommand{\bV}{\textbf{V}}
\newcommand{\bw}{\textbf{w}}
\newcommand{\bW}{\textbf{W}}
\newcommand{\bu}{\textbf{u}}
\newcommand{\bU}{\textbf{U}}
\newcommand{\by}{\textbf{y}}
\newcommand{\bY}{\textbf{Y}}
\newcommand{\bbx}{\textbf{x}}
\newcommand{\bX}{\textbf{X}}
\newcommand{\bz}{\textbf{z}}
\newcommand{\bZ}{\textbf{Z}}
\newcommand{\beps}{\boldsymbol{\varepsilon}}
\newcommand{\bphi}{\boldsymbol{\phi}}
\newcommand{\bPhi}{\boldsymbol{\Phi}}
\newcommand{\bpsi}{\boldsymbol{\psi}}
\newcommand{\bPsi}{\boldsymbol{\Psi}}
\newcommand{\bomega}{\boldsymbol{\omega}}
\newcommand{\bsigma}{\boldsymbol{\sigma}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}
\newcommand{\bxi}{\boldsymbol{\xi}}
\newcommand{\aaa}{\`a}
\newcommand{\eee}{\`e}
\newcommand{\iii}{\`i}
\newcommand{\ooo}{\`o}
\newcommand{\uuu}{\`u}
\newcommand{\aaaa}{\'a}
\newcommand{\eeee}{\'e}
\newcommand{\iiii}{\'i}
\newcommand{\oooo}{\'o}
\newcommand{\uuuu}{\'u}
\newcommand{\AAA}{\`A}
\newcommand{\EEE}{\`E}
\newcommand{\III}{\`I}
\newcommand{\OOO}{\`O}
\newcommand{\UUU}{\`U}
\newcommand{\AAAA}{\'A}
\newcommand{\EEEE}{\'E}
\newcommand{\IIII}{\'I}
\newcommand{\OOOO}{\'O}
\newcommand{\UUUU}{\'U}
\newcommand{\ND}{\mathcal{ND}}
\newcommand{\RT}{\mathcal{RT}}

%% argmin argmax
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}


%%% theorems
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem*{remark}{Remark}
\renewcommand\qedsymbol{$\blacksquare$}

%%% norm and abs
\newcommand\norm[1]{\left\lVert#1\right\rVert}
\newcommand\abs[1]{\left\vert#1\right\vert}


\begin{document}
\maketitle
\section{Introduction}
The least-square formulation of linear elasticity has been developed in \cite{CS04}, by introducing a functional which is the sum of the squared $L^2$ norms of the residuals of the equilibrium and constitutive equations. In this way, displacement $\bu \in H^1(\Omega)$ and stress $\bsigma \in H(\tdiv,\Omega)$ are considered as independent,  giving rise to a mixed weak form. With respect to the standard primal displacement formulation, several are the advantages of this approach. First, the stress can be directly accessed, which can make the treatment of the elasto-plasticity (see \cite{Sta07}) and friction cases easier. Second, the Lam{\eeee} parameters are not restricted to a limited range of values: indeed, incompressible solids can be treated with no additional effort. Third, the least-square functional is a reliable and efficient a posteriori error estimator. All these properties suggested the generalization of  \cite{CS04} to contact, as shown in  \cite{KMS17} for the Signorini's problem. The respective discretization is carried out by conforming finite element spaces: continuouse piecewise linear functions for the displacement and  Raviart-Thomas elements of the lowest order for the stress.\\
Different tecniques for the solution of discrete contact problems in the displacement formulation have been proposed. A typical one is the projected Gau{\ss}-Seidel, whose behaviour unfortunately deteriorates by increasing the size of the problem. Therefore multilevel approaches  are preferred. Here we want to extend to the least-square setting the monotone multilevel exposed in \cite{KK01}, while for the other methods we refer the reader to the citations therein. In particular, the monotone multilevel aims to compute the solution of the discrete problem by adding to the current iterate fine and coarse corrections that actually minimize the energy functional. Effectively the framework of the least-square linear elasticity for contact problem perfectly adapts to this case. Investigating this strategy is actually the main goal  of the present paper. Nevertheless the primal and the dual variables belong to different spaces, i.e $\bu \in H^1(\Omega)$ and $\bsigma \in H(\tdiv,\Omega)$. And since $H^1 \subset H(\tdiv,\Omega)$, schemes applied to the primal case cannot be transferred straightforwardly to the mixed one. \\
The most important difference between $H(\tdiv,\Omega)$ and $H^1(\Omega)$ consists in the kernels of the divergence, which contains all divergence-free functions, and of the gradient, which consists only of constants. Between the two, the kernel of the gradient operator is smaller and its elements can be well represented on coarse meshes. On the other hand, the kernel of the divergence is very large and its functions can have large gradients, so that their representation on coarse meshes can be very poor. In order to circumvent this drawback, 
some variants of multilevel methods for $H(\tdiv,\Omega)$ have been studied, at least for the linear case. A general overview can be found in \cite{XCN09}.  In \cite{Hip97} a geometric multigrid has been proposed. Then in \cite{HX07} a more general framework for dealing algebraic and geometric multigrid has been developed. All these approaches are based on the Helmoltz decomposition, which is a tool used not only in theory but also in the implementation. In particular, the different components in the Helmoltz decomposition can be expressed as functions of certain potentials, which are tackled separately. To this aim, various projections into the potential spaces are needed. However in this paper we take advantage of the work proposed in \cite{AW97},~\cite{AFW00},~\cite{Arn}. In this way, no potential space has to be considered, although a proper patch smoother is required. Moreover this smoother can be extended to the least-square formulation as proposed in \cite{Sta00}. In this way, we tackle all together not only the different components of the Helmoltz decomposition for the stress, but also the displacement.\\
So far, only multilevel for linear problems have been discussed. Nevertheless the Signorini's problem is non-linear. Of course by taking advantage of the active set method, for each arising linear problem, a linear multilevel method could be used. However in this way the non-linearities would not appear into the multilevel cycles, but only in the active set. The main advantage of a monotone multilevel method is that it is able to deal with constraints inside the multilevel cycle itself.  \\
The article is organized in the following way. In the second section, we introduce the problem. In the third one, existence and uniqueness of the solution are shown. In the fourth section a monotone multilevel strategy is proposed, while in the fifth one some non-linear projection operators for the constraints are introduced.
\section{Definition of the problem }
 Let $\Omega$ be an open, bounded, connected subset of $\mathbb{R}^d$, where $d=2,3$ is the dimension of the problem. The boundary $\partial \Omega$, Lipschitz and continuous, is the union of two open disjoint subsets $\partial \Omega= \Gamma_D \cup \Gamma_N$, with  $\Gamma_D \neq \emptyset$ and  $\Gamma_D \cap\Gamma_N = \emptyset$. Then let $\bff=(f_1,...,f_d)^T$ be the body force, $\bu=(u_1,...,u_d)^T$ the displacement field,  $\bsigma=(\sigma_{ij})_{d \times d}$ the stress tensor. The \textit{strong formulation of linear elasticity} is the following:\textit{ find $\bu$, $\bsigma$ such that}:
\begin{align*}
\begin{cases}
\text{div} \bsigma + \bff=0 & \Omega  \qquad \text{momentum balance equation}\\
\mathcal{A} \bsigma - \boldsymbol{\varepsilon}(\bu)=0 &\Omega \qquad \text{constitutive law}\\
\bu = \bu^D & \Gamma_D\qquad \text{Dirichlet BC}\\
\bsigma  \bn = \bt^N & \Gamma_N\qquad \text{Neumann BC}\\
\end{cases} 
\end{align*}
where the linearized strain tensor $\boldsymbol{\varepsilon}(\bu)= \text{sym} (\nabla \bu)$ is the symmetric part of the displacement gradient, $\mathcal{A}=\dfrac{1}{2 \mu} \left(\bsigma-\dfrac{\lambda}{d \lambda + 2 \mu } \text{tr} \bsigma \bI\right)$ is the compliance tensor with $\text{tr}$, $d$, $\lambda$ and $\mu$ denoting respectively the trace operator, the dimension of the problem and the Lam\eeee${}$ parameters.\\
Now let $\Gamma_C$ be the contact boundary such that $ \partial \Omega=\Gamma_C \cup  \Gamma_D \cup  \Gamma_N$, $\Gamma_i \cap  \Gamma_j =\emptyset$ for $i,j=D,N,C, i \neq j $, and $\Gamma_D \neq \emptyset$. Then, by adding the following constraints:
\begin{align*}
\begin{cases}
\bu \cdot \bn_o - g  \leq 0 & \Gamma_C \qquad \text{impenetrability}\\
(\bsigma \bn) \cdot \bn_o \leq 0 &\Gamma_C \qquad \text{direction of the surface pressure}\\
 \left(\bu \cdot \bn_o -g \right) \left( (\bsigma \bn) \cdot \bn_o \right) =0 & \Gamma_C \qquad \text{complementarity condition}
  \\
  (\bsigma \bn) \cdot \bt_o = 0 &\Gamma_C \qquad  \text{frictionless condition}
\end{cases}
\end{align*}
the strong formulation of contact for linear elasticity is finally obtained. Here $\bn$ represents the outward normal of the body, while $\bn_o$ and $\bt_o$ respectively represent the normal and the tangent vectors of the obstacle. The gap function $g$ is instead the distance in the normal direction between the obstacle and the body. Here the first condition means that no penetration can occur between the body and the obstacle. The second condition implies that, whenever contact forces arise, they have to be of compression and no adhesion is permitted. The third condition is a classic complementarity condition of the first two. 
The last one states that only normal stresses can arise.
Finally, by confusing the normal and the tangent vectors of the obstacle with the ones of the body, i.e. $\bn \approx\bn_o$ and $\bt \approx \bt_o$, the linearized contact formulation for linear elasticity is recovered (see \cite{Kik88}). \\
In general, from the strong formulation of the contact linear elasticity, different variants of weak forms can be derived. In the following, a list of motivations that retraces the one in \cite{CS04}, is presented. By substituing the constitutive equation ($\bsigma = \mathcal{C}\boldsymbol{\varepsilon}(\bu)$, with $\mathcal{C}=\mathcal{A}^{-1}$ the elasticity tensor) into the momentum balance one, the displacement formulation is consequently obtained. The displacement $\bu$, belonging to $ H^1(\Omega)$, is the only unknown and the stress $\bsigma$, belonging only to $L^2(\Omega)$, is derived \textit{a posteriori} and cannot be carefully approximated. Furthermore locking phenomena can arise for incompressible or nearly incompressible solids ($\lambda \gg 1$ or $\lambda \to \infty$).\\
To achieve a better approximation of the stress, the mixed formulation by Hellinger-Reissner can be used (\cite{BF12}). Given the energy-functional $\mathcal{J}(\bu,\bsigma)=\frac{1}{2}\left(\mathcal{A} \bsigma, \bsigma \right) + \left(\nabla \cdot \bsigma + \bff, \bu \right)  $, both displacement and stress $(\bu,\bsigma)$ are unknowns of the problem, respectively belonging to $  L^2(\Omega)^d  \times  H_{\text{div},S}(\Omega)^d$ , where $H_{\text{div},S}(\Omega)^d$ is the space of symmetric tensors in $H_{\text{div}}(\Omega)$. In this case, in order to satisfy the inf-sup condition in the discrete setting, a stable combination of finite element spaces is needed. Although such spaces have been built (\cite{CS04}), the number of degrees of freedom they require is very large. Furthermore the corresponding linear system is a saddle point problem, that in general is difficult to solve.\\
The approach that is here presented is based on the LS principle (\cite{Boc09}, \cite{BMM97}, \cite{YL97}). The main idea behind it is to build a fictitious functional as the weighted sum of the squared $L^2$-norms of the residual equations. Unlike the previous cases, now it is required more regularity on both variables: $\bu \in H^1(\Omega)$, $\bsigma \in H(\tdiv,\Omega)$. With respect to the Hellinger-Reissner formulation, the symmetry of the stress tensor is not demanded. Indeed, as it is shown in \cite{CS04}, $\norm{
\bsigma-\bsigma^T}\leq C \norm{\mathcal{A}\bsigma -\boldsymbol{\varepsilon}(\bu)}$. Therefore, by reducing the residual of the constitutive law, the asymmetry is reduced as well. In particular, spaces that would be useful for the analysis are the following: 
\begin{align*}
&H_D^1(\Omega)=\left\lbrace \bv \in \left[ H^1(\Omega)\right]^d, \quad \bv|_{\Gamma_D}=\bu^D   \:\: \text{on} \: \Gamma_D \right\rbrace &&
H_{D,0}^1(\Omega)=\left\lbrace \bv \in \left[ H^1(\Omega)\right]^d, \quad \bv|_{\Gamma_D}=\textbf{0}    \:\:  \text{on} \: \Gamma_D \right\rbrace \\
&H_N(\tdiv,\Omega)=\left\lbrace \btau \in \left[ H(,\tdiv, \Omega)\right]^d, \quad \btau \bn |_{\Gamma_N}=\bt^N   \:\:  \text{on} \: \Gamma_N
\right\rbrace &&
H_{N,0}(\tdiv,\Omega)=\left\lbrace \btau \in \left[ H(,\tdiv, \Omega)\right]^d, \quad \btau \bn |_{\Gamma_N}=\textbf{0}
 \:\: \text{on} \: \Gamma_N \right\rbrace 
\end{align*}
Then, relying on the formulation given in \cite{KMS17}, we define the linear elasticity LS functional $\mathcal{F}$ and the corresponding augmented LS functional $\mathcal{J}$ for contact:
\begin{align*}
&\mathcal{F}(\bu,\bsigma;\bff)=C_{eq} ||\text{div} \bsigma+\bff||_{L^2(\Omega)^d}^2+C_{const}||\mathcal{A}\bsigma -\boldsymbol{\varepsilon}(\bu)||_{L^2(\Omega)^d}^2 \\
&
\mathcal{J}(\bu,\bsigma;\bff,g)=\mathcal{F}(\bu,\bsigma;\bff)+C_{compl} \langle \bu \cdot \bn -g, (\bsigma \bn) \cdot \bn \rangle_{\Gamma_C}
\end{align*}
So that the problem can be formulated in this way: find $(\bu,\bsigma)$ such that
 \begin{align}
 &(\bu,\bsigma)=\argmin \limits_{(\bu,\bsigma) \in K}\mathcal{J}(\bu,\bsigma;\bff,g)\\
 &K=
 \left\lbrace 
  \left(\bu,  \bsigma \right)  \in  
 H_D^1(\Omega)\times H_N(\tdiv,\Omega)  : \quad 
 \bu \cdot \bn - g  \leq 0, \:\:  (\bsigma \bn) \cdot \bn \leq 0, \:\: (\bsigma \bn) \cdot \bt =\textbf{0}  \:\: \text{on}  \: \: \Gamma_C
\right\rbrace 
\label{MinimizationProblem}
\end{align}
The complementarity condition on $\Gamma_C$ is a non-linear term. Defining the convex set $K$ by adding also this requirement would be cumbersome, at least from a computational perspective. On the other hand, augmenting the functional with this term seems a more natural choice. \\
The augmented functional is Gateaux-differentiable and strongly convex, as we will show. Therefore the problem (\ref{MinimizationProblem}) can be reformulated in the following way: find $(\bu,\bsigma) \in K$ such that
\begin{align}
\label{LScontactVI}
\begin{cases}
&
\left\langle \dfrac{\partial \mathcal{J}(\bu,\bsigma;\bff,g)}{\partial \bu }, \bv-\bu \right\rangle =
-2 \left(\mathcal{\bsigma}-\boldsymbol{\varepsilon}(\bu), \boldsymbol{\varepsilon}(\bv-\bu) \right)+\langle \bn \cdot \left( \bsigma \bn\right), \bn \cdot (\bv -\bu)\rangle_{\Gamma_C}
\geq 0 \\\\
&
\left\langle \dfrac{\partial \mathcal{J}(\bu,\bsigma;\bff,g)}{\partial \bsigma }, \btau-\bsigma \right\rangle =
2\left(\text{div}\bsigma +\bff, \tdiv (\btau-\bsigma) \right)
+ 2 \left( 
\mathcal{\bsigma}-\boldsymbol{\varepsilon}(\bu),\mathcal{\btau-\bsigma}
\right) +\langle \bn \cdot \bu-g, \bn \cdot 
\left(\btau- \bsigma \right)\bn \rangle_{\Gamma_C}
\geq 0 
\end{cases}
\qquad  \forall (\bv,\btau) \in K
\end{align}
\section{Existence and uniqueness of the solution}
Now we want to prove that the minimization problem has a unique solution $(\bu,\bsigma)$. To this aim,  let us define the following norm $M(\bs,\bw): H_D^1(\Omega) \times H_N(\tdiv,\Omega) \to \mathbb{R}$:
\begin{align*}
&M(\bs,\bw)= \|  \boldsymbol{\varepsilon}(\bw) \|_{L^2} +  \| \btau \|_{H_{div}}^2 =  \|  \boldsymbol{\varepsilon}(\bw) \|_{L^2}^2 +  \| \bs \|_{L^2}^2 +  \| \tdiv \bs \|_{L^2}^2 
\end{align*}
Then we can prove:
\begin{lemma}
$\forall \bu, \bv \in H_D^1(\Omega)$, $\forall \bsigma, \btau \in H_N(\tdiv,\Omega)$, let $\bw=\bu-\bv$ and $\bs=\bsigma-\btau$. Then exist $C_1$ and $C_2$ such that:
\begin{align*}
M(\bs,\bw) C_1 \leq \mathcal{J}(\bw,\bs;0,0) \leq C_2 M(\bs,\bw)
\end{align*}
where:
\begin{align}
C_1= \left(\text{max} \left(4,   \dfrac{  1 + 4 \mu + 10 \mu^2 + 16 \mu^3} {(1+2 \mu) \mu^2} \right) 
\right)^{-1}
\end{align}
\end{lemma}
\begin{proof}
The proof is similar to the the theorem 3.1 in \cite{CS04}. Although the functional $\mathcal{J}$ is defined only with the $L^2$ norms of the residuals, here we also consider non-homogeneous boundary conditions and the contact boundary. \\
The upper bound can be easily shown by using $\|\mathcal{A}\btau\| \leq \dfrac{1}{2 \mu} \| \btau \|$, the triangle, Young and trace inequalities. \\
In order to prove the inequality from below, it is sufficient to bound all the terms in $M$ with the functional. Knowing that $\|\mathcal{A}\btau\| \leq \dfrac{1}{2 \mu} \| \btau \|$:
\begin{align*}
 \| \text{div}\bs\|_{L^2}^2  + \| \boldsymbol{\varepsilon}(\bw) \|^2 \leq  \| \text{div}\bs\|_{L^2}^2 +2 \| \boldsymbol{\varepsilon}(\bw) - \mathcal{A}\bs\|^2 + 2 \| \mathcal{A}\bs\|^2  \leq 2 \mathcal{F}(\bw,\bs;0) +  \dfrac{1}{2 \mu }\| \bs\|^2
\end{align*} 
Therefore it is now sufficient to bound $\dfrac{2 \mu +1}{2 \mu} \| \bs \|_{L^2} $. 
We just exploit $(\mathcal{A}\bs,\bs )\geq \dfrac{1}{2 \mu}  \| \bs \|^2$:
\begin{align*}
(\mathcal{A}\bs,\bs ) &= (\mathcal{A}\bs - \boldsymbol{\varepsilon}(\bw),\bs ) + (\boldsymbol{\varepsilon}(\bw),\bs)=  (\mathcal{A}\bs - \boldsymbol{\varepsilon}(\bw),\bs ) + (\bs - \frac{\bs -\bs^T}{2},\nabla \bw)\\
&=(\mathcal{A}\bs - \boldsymbol{\varepsilon}(\bw),\bs )-(\text{div} \bs,\bw) +\int_{\partial \Omega} \bs \bn \cdot \bw - \left(\bs-\bs^T, \nabla \bw \right)\\ 
& \leq \|  \mathcal{A}\bs - \boldsymbol{\varepsilon}(\bw) \| \| \bs\| +\|\text{div} \bs\| \| \bw \| +\|\frac{\bs-\bs^T}{2}\| \|\nabla \bw \|+\int_{\partial \Omega} \bs \bn \cdot \bw \\
& \leq \mu \|  \mathcal{A}\bs - \boldsymbol{\varepsilon}(\bw) \|^2+    \dfrac{1}{4 \mu} \| \bs\|^2
+  \|\boldsymbol{\varepsilon}(\bw) \| \left( \|\text{div} \bs\| + \|\frac{\bs-\bs^T}{2}\|\right)+\int_{\partial \Omega} \bs \bn \cdot \bw 
\end{align*}
And by using $\| \bs -\bs^T\| \leq 4 \mu \|\mathcal{A}\bs - \boldsymbol{\varepsilon}(\bw) \|$, $\| \bs \|^2 \leq 2 \mu (\mathcal{A} \bs, \bs)$, 
$\| \mathcal{A}\bs - \boldsymbol{\varepsilon}(\bw)\| \leq  \mathcal{F}(\bw,\bs;0)^{1/2}$, $\| \bs \| \leq  \mathcal{F}(\bw,\bs;0)^{1/2}$, $\| \bs -\bs^T\| \leq 4 \mu \|\mathcal{A}\bs - \boldsymbol{\varepsilon}(\bw) \|$:
\begin{align*}
(\mathcal{A}\bs,\bs ) & \leq 2 \mu \|  \mathcal{A}\bs - \boldsymbol{\varepsilon}(\bw) \|^2+ 2 \left( 1+ 2 \mu \right) \mathcal{F}(\bw,\bs;0)^{1/2}  \|\boldsymbol{\varepsilon}(\bw) \| 
+\int_{\partial \Omega} \bs \bn \cdot \bw 
\end{align*}
Now it is exploited again $ \|  \mathcal{A}\bs - \boldsymbol{\varepsilon}(\bw) \|^2\leq \mathcal{F}(\bw,\bs;0) $ and $ \| \boldsymbol{\varepsilon}(\bw) \|  \leq  \mathcal{F}(\bw,\bs;0)^{1/2} + \| \mathcal{A} \bs\| \leq \mathcal{F}(\bw,\bs;0)^{1/2} +  \dfrac{1}{2 \mu }\| \bs\|$, so that:
\begin{align*}
(\mathcal{A}\bs,\bs ) & \leq (2 +6 \mu)\mathcal{F}(\bw,\bs;0) 
+\dfrac{\left( 1+ 2 \mu \right) }{\mu}\mathcal{F}(\bw,\bs;0)^{1/2}  \| \bs \| 
+2 \int_{\partial \Omega} \bs \bn \cdot \bw 
\end{align*}
By Young's inequality:
\begin{align*}
(\mathcal{A}\bs,\bs ) & \leq 2 (2 +6 \mu)\mathcal{F}(\bw,\bs;0) 
+2 \dfrac{ \left( 1+ 2 \mu \right)^2 }{2 \mu^2}\mathcal{F}(\bw,\bs;0)
+4 \int_{\partial \Omega} \bs \bn \cdot \bw\\
& \leq \dfrac{4 \mu^2 + 12 \mu^3 + 1 + 4 \mu^2 + 4 \mu}{\mu^2} \mathcal{F}(\bw,\bs;0) +4 \int_{\partial \Omega} \bs \bn \cdot \bw  
\end{align*}
By rearranging the terms:
\begin{align*}
M(\bs,\bw)&=  \|  \boldsymbol{\varepsilon}(\bw) \|_{L^2}^2 +  \| \bs \|_{L^2}^2 +  \| \text{div} \bs \|_{L^2}^2\\
& \leq 2 \mathcal{F}(\bw,\bs;0) +  \dfrac{4 \mu^2 + 12 \mu^3 + 1 + 4 \mu^2 + 4 \mu}{(1+2 \mu) \mu^2}  \mathcal{F}(\bw,\bs;0)  +4 \int_{\partial \Omega} \bs \bn \cdot \bw \\
&\leq \dfrac{1}{C_1} \left( \mathcal{F}(\bw,\bs;0) + \int_{\partial \Omega} \bs \bn \cdot \bw\right) \\
&=\dfrac{1}{C_1} \left( \mathcal{F}(\bw,\bs;0) + \langle \bs \bn \cdot \bn,  \bw \cdot \bn \rangle_{\Gamma_C}\right) 
\end{align*} 
where we have exploited $\bw|_{\Gamma_D}= \textbf{0}$, $\bs \bn|_{\Gamma_N} =\textbf{0}$, $\left(\bs \bn\right)\cdot \bt=0$
\end{proof}
\begin{lemma}
The augmented LS functional is strongly convex and coercive.
\end{lemma}
\begin{proof}
The functional $\mathcal{F}(\bu,\bsigma;\bff) $ is convex, but the complementarity term is not. However the whole functional $\mathcal{G}(\bu,\bsigma,
\bff,g) $ is strongly convex:
\small
\begin{align*}
\mathcal{J}( t \bu + (1-t) \bv, t \bsigma + (1-t) \btau; \bff,g)
&= t \mathcal{J}( \bu ,\bsigma ; \bff,g) + (1-t)\mathcal{J}(  \bv,  \btau; \bff,g)+ t(t-1) \mathcal{J}(\bu-\bv,\bsigma-\btau;0,0)\\
& \leq t  \mathcal{J}( \bu ,\bsigma ; \bff,g)+ (1-t) \mathcal{J}( \bv ,\btau ;\bff,g)+ t(t-1)C_1M(\bu-\bv,\bsigma-\btau)
\end{align*}
\normalsize
where the last inequality holds due to the previous result. It is also known the $\mathcal{J}(   t \bu + (1-t) \bv, t \bsigma + (1-t) \btau; \bff,g)\geq0$ $\forall \bsigma, \btau, \bu, \bv$ in the adimissible set. Then fix $t \in (0,1)$, choose $\bv$, $\btau$ as the minimizer of the problem, so that $\mathcal{J}(  \bv,  \btau, \bff,g)=0$, and let $\norm{\bu}_{H^1(\Omega)}\to \infty$, $\norm{\bsigma}_{H^N(\tdiv,\Omega)} \to \infty$:
\begin{align*}
\dfrac{1}{C_1(1-t)}\mathcal{J}( \bu ,\bsigma , \bff,g)& \geq  M(\bu-\bv,\bsigma-\btau) =\\
&( \|  \boldsymbol{\varepsilon}(\bu ) \|_{L^2}^2  +  \|  \boldsymbol{\varepsilon}(\bv ) \|_{L^2}^2 -2 \| \boldsymbol{\varepsilon}(\bu )\|_{L^2} \| \boldsymbol{\varepsilon}(\bv )\|_{L^2} +
  \| \btau \|_{H_{div}}^2+ \| \bsigma \|_{H_{div}}^2 - 2  \| \btau \|_{H_{div}}  \| \bsigma \|_{H_{div}}) \to \infty
\end{align*}
The right handside is a quadratic expression in $ \| \bsigma \|_{H_{div}}$ and $\|  \boldsymbol{\varepsilon}(\bu ) \|_{L^2}$. By the generalized Korn's inequality, if $\norm{\bu}_{H^1(\Omega)}\to \infty$, also $\norm{\boldsymbol{\varepsilon}(\bu)}_{L^2(\Omega)}\to \infty$.
\end{proof}
\begin{lemma}
It exists a unique minimizer $(\bu,\bsigma) \in K$ of the augmented LS functional $ \mathcal{J}( \bu ,\bsigma , \bff,g)$.
\end{lemma}
\begin{proof}
The proof follows by strong convexity and coercivity of the functional.
\end{proof}

\section{Monotone Multilevel}
Let $\mathcal{T}_1$ be a partition of $\Omega$ into finite elements $\tau$ (triangles in 2D or tetrahedra in 3D), with meshwidth parameter $h_1=\max_{\tau \in \mathcal{T}_1}\text{diam}(\tau)$ and $\Gamma_{C,1}=\mathcal{T}_1|_{\Gamma_C}$ . Then recursively, for $j=2,...,J$,  define $\mathcal{T}_j$, with the corresponding $h_j$ and $\Gamma_{C,j}$, as the uniform refinement  of $\mathcal{T}_{j-1}$. We also denote by $\mathcal{N}_j$, $\mathcal{E}_j$, $\mathcal{F}_j$ the sets of vertices, edges and faces of the mesh $\mathcal{T}_j$, and with $N_j$, $E_j$, $F_j$ their cardinality. Furthermore, let us consider two levels $j$, $k$ and the corresponding vertices $\nu_j$, $\nu_k$, edges $\varepsilon_j$, $\varepsilon_k$, faces $\phi_j$, $\phi_k$ and elements $\tau_j$, $\tau_k$. We define the $\bigtriangleup$-patch of $\#$ as: 
\begin{align*}
P_{\#}^{\bigtriangleup}=
\left\lbrace
\bigtriangleup: \:
\# \in \bigtriangleup \
    \right\rbrace
    \qquad \#=\nu_j,\varepsilon_j,\phi_j,\tau_j, \quad \bigtriangleup =\nu_k,\varepsilon_k,\phi_k,\tau_k
\end{align*}
Now let $P^1(\mathcal{T}_j)$  and $\text{RT}_0(\mathcal{T}_j)$ be respectively the continuous piecewise linear functions space and the lowest order Raviart-Thomas space defined on the tassellation $\mathcal{T}_j$. The related interpolation operators from level $j$ to level $j+1$ are defined as follows, if $n_{\phi_{j+1}}$ is the normal related to the face $\phi_{j+1}$:
\begin{align*}
&P_j^{j+1}: P^1(\mathcal{T}_j) \to P^1(\mathcal{T}_{j+1})
\qquad
 (P_j^{j+1} u - u )|_{\nu_{j+1}} =0\qquad \forall \nu_{j+1} \in \mathcal{N}_{j+1}, \:\: \forall \bu \in P^1(\mathcal{T}_j)
\\
&\Pi_j^{j+1}: \text{RT}_0(\mathcal{T}_j) \to \text{RT}_0(\mathcal{T}_{j+1}) \qquad
\int_{\phi_{j+1}} (\Pi_j^{j+1} \sigma - \sigma) n_{j+1}  ds =0\qquad \forall \phi_{j+1} \in \mathcal{F}_{j+1}, \:\: \forall \sigma \in  \text{RT}_0(\mathcal{T}_j)
\end{align*}
For $j=1,...,J$ we also define the following finite element spaces:
\begin{align*}
& U_j=\left\lbrace \bu \in \left[
P^1(\mathcal{T}_j) \right]^d
  \right\rbrace \qquad
\Sigma_j=\left\lbrace \bsigma \in \left[
\text{RT}_0(\mathcal{T}_j)\right]^d
  \right\rbrace
    \qquad
  X_j =U_j \times \Sigma_j
\end{align*}
whose basis functions belong to $\Lambda_{U_j}$, $\Lambda_{\Sigma_j}$, $\Lambda_{X_j}$. The $P^1$ fand RT$_0$ functions are defined respectively on each node $\nu \in \mathcal{N}_j$ and face $\phi \in \mathcal{F}_j$. Therefore:
\begin{align*}
\Lambda_{U_j}
=
\left\lbrace
\blambda_{j,\nu}, \:\: \nu \in \mathcal{N}_j 
  \right\rbrace ,
  \quad
  \Lambda_{\Sigma_j}
=
\left\lbrace
\blambda_{j,\phi}, \:\: \phi \in \mathcal{F}_j 
  \right\rbrace ,
  \quad 
  \Lambda_{X_j}=
  \Lambda_{U_j} \cup   \Lambda_{\Sigma_j}
\end{align*}
We can also build the multi-dimensional interpolation operators:
\begin{align}
\label{interpolations}
&\bP_j^{j+1}=\left[ P_j^{j+1} \right]^d : \left[P^1(\mathcal{T}_j)\right]^d \to \left[P^1(\mathcal{T}_{j+1})\right]^d
\qquad
\bPi_j^{j+1}=\left[ \Pi_j^{j+1}\right]^d 
: \left[\text{RT}_0(\mathcal{T}_j)\right]^d \to \left[\text{RT}_0(\mathcal{T}_{j+1})\right]^d 
\end{align}
Moreover in the finite element framework now introduced, it is also possible to consider the discretization of functions of the normal components in  $\left[H^{1/2}(\Gamma_C)\right]^d$ and $\left[H^{-1/2}(\Gamma_C)\right]^d$. The first space is $U_{j,n}$ and consists of continuous functions which are linear on each face $\phi \in\Gamma_C$. The second space is $\Sigma_{j,n}$ and consists of piecewise discontinuous functions which are constant on each face $\phi \in \Gamma_C$. Of course also for these spaces we can define interpolation operators:
\begin{align}
\label{normalinterpolations}
P_{j,n}^{j+1}:U_{j,n} \to U_{j+1,n} \qquad \qquad
\Pi_{j,n}^{j+1}:\Sigma_{j,n} \to \Sigma_{j+1,n}
\end{align}
Furthermore let denote the convex set as:
\begin{align*}
K_J=\left\lbrace
  \bbx_J=(\bu_J, \bsigma_J) \in X_J: \quad \bu_J|_{\Gamma_D}=\bu_J^D , \:  \bsigma_J|_{\Gamma_N}=\bt_J^N, \: \bu_J\cdot \bn_J|_{\Gamma_C}\leq g_J, \: \bn^T(\bsigma_J \bn)  \leq 0, \: \bt_J^T(\bsigma \bn_J) =0
  \right\rbrace 
\end{align*}
where $\bu_J^D$, $\bt_J^N$, $\bn_J$, $g_J$ are suitable approximations in the discrete finite element space and geometry of $\bu^D$, $\bt^N$, $\bn$ and $g$. Of course, due to this approximation, in general $K_J \nsubseteq K$. Moreover let $\bff_J$ be an approximation of $\bff$. We can write $\mathcal{J}_J(\bbx_J)=\mathcal{J}_J(\bu_J,\bsigma_J;\bff,g)=\mathcal{J}(\bu_J,\bsigma_J;\bff_J,g_J)$. The discrete minimization problem is then: find $(\bu_J,\bsigma_J) \in K_J$ such that:
\begin{align}
\label{discreteminimizationproblem}
\mathcal{J}_J(\bu_J,\bsigma_J;\bff_J,g_J)  \leq \mathcal{J}_J(\bv_J,\btau_J;\bff_J,g_J) \quad \forall \: (\bv_J,\btau_J) \in K_J
\end{align}
Whenever it will be no cause of misuderstanding, the subscript $J$ will be omitted from the functional and the unknowns. \\\\
The standard projected Gau{\ss}-Seidel successively minimizes the functional $\mathcal{J}(\bbx)$ in the directions $\lambda_J \in \Lambda_{X_J}$. However the rate of convergence of this method deteriorates for $h_J \to 0$. Such an inconvenient promoted the analysis of multilevel methods that involve coarse grid corrections as well. In particular, the monotone multilevel idea is to extend the minimization process also to low frequency components of the spectrum. Therefore  $\mathcal{J}$ is minimized with respect to all $\lambda_j \in \Lambda_{X_j}$, for $j=1,...,J$.\\
A prerequisite of multilevel methods is that eigenfunctions associated to small eigenvalues can be well represented on coarse meshes. This is automatically satisfied in $H^1$, since the kernel of the gradient operator boils down to costants functions. However the kernel of the divergence operator is very large. All free-divergence functions, also the ones with a large gradient, are admissible. To circumvent this drawback, different strategies have been proposed (\cite{Hip97}, \cite{HX07}). Here we will focus on the one described in \cite{AW97},~\cite{AFW00},~\cite{Arn}, but since the present is a mixed formulation, an extension to primal and dual variables as in \cite{Sta00} is carried out. For each vertex $\nu \in \mathcal{T}_j$, we define the patch $P_{\nu}^{\tau_j}$ as the union of all the elements $\tau_j$ of the same mesh that share the vertex $\nu \in \mathcal{N}_j$. Then the degrees of freedom of interest are the vertex itself f$\nu$ or the displacement and all the internal faces $P_{\nu}^{\phi_j}$ for the stress. We denote by $\lambda_{j,\nu}$ the collection of these degrees of freedom. As usual, on the coarser level $j=1$, the direction is the whole space. 
\begin{align*}
\displaystyle
&
\blambda_{j,\nu} \in \Lambda_{j,\nu}=
  \left\lbrace
  \blambda_{U_j, \nu} \in \Lambda_{U_j}
    \right\rbrace  
  \cup
  \left\lbrace
\blambda_{\Sigma_j, \phi} \in \Lambda_{\Sigma_j}, \: \phi \in \mathcal{F}_j \cap  \in P_{\nu}^{\phi_j}
  \right\rbrace   && j=2,...,J,\:\:\nu \in \mathcal{N}_j \\
  &
  \blambda_{1} =   \left\lbrace
\bigcup\limits_{\nu \in \mathcal{N}_1}
\{
\blambda_{U_1, \nu} \in \Lambda_{U_1} \}
  \right\rbrace 
  \cup
    \left\lbrace
  \bigcup\limits_{\phi \in \mathcal{F}_1}
  \{
\blambda_{\Sigma_1, \phi} \in \Lambda_{\Sigma_j}
\}
  \right\rbrace   && j=1
%&\blambda_{j,\nu} \in \Lambda_{j,\nu}=
%\begin{cases}
%\blambda_{U_j, \nu} \in \Lambda_{U_j}
%  \cup
%  \left\lbrace
%\blambda_{\Sigma_j, \phi} \in \Lambda_{\Sigma_j}, \: \phi \in \mathcal{F}_j \cap  \in P_{\nu}^{\phi_j}
%  \right\rbrace   & j=2,...,J\\
%    \left\lbrace
%\bigcup\limits_{\nu \in \mathcal{N}_1}
%\{
%\blambda_{U_1, \nu} \in \Lambda_{U_1} \}
%  \right\rbrace 
%  \cup
%    \left\lbrace
%  \bigcup\limits_{\phi \in \mathcal{F}_1}
%  \{
%\blambda_{\Sigma_1, \phi} \in \Lambda_{\Sigma_j}
%\}
%  \right\rbrace   & j=1
%  \end{cases}
\end{align*}
Consequently $\mathcal{J}$ has to be minimized with respect to $\lambda_{j,\nu} \in \Lambda_{X_j}$, for $j=J,...,2$ and $\nu=1,...,N_j$, and $\blambda_1$. Since the functional is strongly convex and differentiable, the discrete minimization problem (\ref{discreteminimizationproblem}) can be reformulated as the variational inequality (\ref{LScontactVI}). Let $\bbx_{J,k} \in K_J$ be the $k$-th iterate. Then we define $\bbx_{J,0}=\bbx_{J}^k$ and $\bbx_{j,0}=\bbx_{j+1,N_{j+1}}$, for $j=J-1,...,1$. We compute a sequence of intermediate iterates $\bbx_{j,\nu} =\bbx_{j,\nu-1}+\bc_{j,\nu}$ by solving:
\begin{align}
\label{exactlocalproblem}
&\mathcal{J}(\bbx_{j,\nu}+\bc_{j,\nu}) \leq \mathcal{J}(\bbx_{j,\nu}+\by) \quad \forall \by \in K_{j,\nu}^{*} \qquad j=J,...,2, \quad \nu=1,...,N_j\\
&\mathcal{J}(\bbx_{2,N_2}+\bc_{1}) \leq \mathcal{J}(\bbx_{2,N_2}+\by) \quad \forall \by \in K_{1}^{*} \qquad j=1
\end{align}
where the local closed convex sets $K_{j,\nu}$  and $K_1^*$ are defined as follows:
\begin{align}
\label{exactlocalconvexset}
K_{j,\nu}^{*}(\bbx_{j,\nu})=\left\lbrace
\by \in \text{span}\{\blambda_{j,\nu}\}: \quad \by +\bbx_{j,\nu} \in K_J
  \right\rbrace  \qquad
  K_{1}^{*}(\bbx_{2,N_2})=\left\lbrace
\by \in \text{span}\{\blambda_{1}\}: \quad \by +\bbx_{2,N_2} \in K_J
  \right\rbrace 
\end{align}
In order to compute the solution of these local problems,  a comparison with the constraints on the fine level is needed.
However a fundamental feature of multilevel algorithms for having linear complexity is that the number of each operations on a given level $j$ is proportional to the number of degrees of freedom on the same level $j$ (\textbf{is this true for the level 1? I do not think so}).
Then it is obvious that a check of coarse corrections with respect to fine constraints would imply a violation of this condition and, consequently, a suboptimal complexity. To recover an optimal complexity, only an approximate solution, instead of the exact one,  can be taken into consideration for coarser levels. To this aim, we define approximate convex sets $K_j$ and, consequently, proper coarse constraints which will depend on the current iterate and on the corrections on the higher levels. Two specific non-linear projections, one for the normal displacement and the other for the pressure, will be later investigated. 
\begin{remark}[] In minimizing the functional $\mathcal{J}$ along the directions $\lambda_{j,\nu}$, the order has been chosen in this way: $j=J,...,1$ and, for a fixed level $j$, from $\nu=1$ to $\nu=N_j$. This scheme corresponds only to a pre-smoothing. Anyhow, after this pre-smoothing, the order can be inverted again, i.e. $j=1,...,J$, $\nu=N_j,...,1$, so that a post-smoothing with a overall symmetric cycle is recovered.
\end{remark}
In order to properly describe contact conditions also on coarser levels, it is wise to locally change the coordinate system of the contact boundary $\Gamma_C$. In this way, the scalar constraints have to be checked directly on the normal components and not on some linear combinations of the unknown.
Let $\nu \in \mathcal{N}_j  \cap \Gamma_{C,j}$ and $\bn_{\nu}$ the obstacle normal in $\nu$. Then consider the vector $ \bu_{\nu} \in \mathbb{R}^d$ that contains the degrees of freedom of the displacement in $\nu$. Define the Householder transformation $\bH_{\nu}$ relative to the ouward normal $\bn_{\nu} $ and the local displacement in the normal-tangent coordinate system $\bu_{\nu,nt}$ (the first coordinate is the normal one) as:
\begin{align*}
\bu_{\nu,nt}= \bH_{\nu} \bu_{\nu} 
\qquad \qquad 
\bH_{\nu}= \bI- 2\: \bn_{\nu} ^T \bn_{\nu} 
\end{align*}
A similar argument has to be applied to the stress components. For each face $\phi \in \Gamma_{C,j}$, we can express the vector unknown $\bSigma_{\phi}$ in terms of the normal and tangent forces $\bSigma_{\phi,nt}$. It is not convenient to use direclty the HouseHolder transformation $\bH_{\phi}$ relative to the face normale $\bn_{\phi}$, because we have no control on the sign of $\left( \blambda_{j,\phi}  \cdot \bn_{\phi}  \right)$. In its place, it is preferrable the transformation $\bQ_{\phi}$:
\begin{align*}
\bsigma \bn_{\phi} = \left( \bphi_{\phi} \cdot \bn_{\phi} \right) \bSigma_{\phi} = \bH_{\phi} \bSigma_{\phi,nt} \quad
 \iff \quad \bSigma_{\phi} = \dfrac{1}{  \left( \bphi_{\phi} \cdot \bn_{\phi} \right)}\bH_{\phi} \bSigma_{\phi,nt} = \bQ_{\phi} \bSigma_{\phi,nt}
\end{align*}
In this way the first component of $\bu_{\nu,nt}$/$\bSigma_{\phi,nt}$ is actually positive in the direction of the normal $\bn_{\nu}$/$\bn_{\phi}$, with $\bH_{\nu}$/$\bQ_{\phi}$ orthogonal. Furthermore the constraints can be direclty compared with the coefficients of the functions in the new basis. Computationally speaking, this is a simplification that does not have to be underestimated.  \\
All the degrees of freedom on the contact boundary will be treated as normal or tangent. The relative change of coordinates is equivalent to a change of basis, so that all the previous definitions of $\Lambda_{U_j,\nu}$, $\Lambda_{\Sigma_j,\nu}$, $\Lambda_{j,\nu}$ have to be consequently adapted:
\begin{align*}
&\Lambda_{U_j,nt} =
\left\lbrace
\blambda_{U_j,\nu,nt}
,\quad \nu \in \mathcal{N}_j
  \right\rbrace 
 \qquad \qquad
\blambda_{U_j,\nu,nt}=
\begin{cases}
\blambda_{U_j,\nu} \bH_{\nu} &\nu \in \Gamma_{C,j} \\
\blambda_{U_j,\nu,nt}=\blambda_{U_j,\nu}  & \nu \notin \Gamma_{C,j}
\end{cases} \quad  \qquad  \qquad j=1,...,J,\:\:\nu \in \mathcal{N}_j \\
&\Lambda_{\Sigma_j,nt} =
\left\lbrace
\blambda_{\Sigma_j,\phi,nt}
,\quad \phi \in \mathcal{F}_j
  \right\rbrace 
 \qquad \qquad
 \blambda_{\Sigma_j,\phi,nt}=
\begin{cases}
\blambda_{\Sigma_j,\phi,nt} \bQ_{\nu} & \phi \in \Gamma_{C,j}\\
\blambda_{\Sigma_j,\phi,nt}  & \phi \notin \Gamma_{C,j}\\
\end{cases} \qquad  \qquad  \qquad j=1,...,J,\:\:\nu \in \mathcal{N}_j \\
  &
\blambda_{j,\nu,nt} \in \Lambda_{j,\nu,nt}=
  \left\lbrace
  \blambda_{U_j, \nu,nt} \in \Lambda_{U_j,nt}
    \right\rbrace  
  \cup
  \left\lbrace
\blambda_{\Sigma_j, \phi,nt} \in \Lambda_{\Sigma_j,nt}, \: \phi \in \mathcal{F}_j \cap  \in P_{\nu}^{\phi_j}
  \right\rbrace    \qquad  \:\: \quad   \qquad j=2,...,J,\:\:\nu \in \mathcal{N}_j \\
  &
  \blambda_{1,nt} =   \left\lbrace
\bigcup\limits_{\nu \in \mathcal{N}_1}
\{
\blambda_{U_1, \nu,nt} \in \Lambda_{U_1,nt} \}
  \right\rbrace 
  \cup
    \left\lbrace
  \bigcup\limits_{\phi \in \mathcal{F}_1}
  \{
\blambda_{\Sigma_1, \phi,nt} \in \Lambda_{\Sigma_j,nt}
\}
  \right\rbrace   \qquad  \quad \quad  \:\:\: \qquad  \qquad  \qquad j=1
\end{align*}
It is important to notice that the change of basis has a direct impact on the system and on the interpolation operators. Let $\bH$ be the global Householder matrix, which collects all the local matrices $\bH_{\nu}$ and $\bQ_{\phi}$, while is the identity on interior degrees of freedom. This operator can be used to redifine \textit{all} the quantities in the normal-tangent coordinate system. However, for the sake of simplicity of notation, from now on we will omit the relative subscript $_{nt}$ and we will denote the normal or tangent components by the notation: $[\cdot]_i$, for $i=n,t$. 
\section{Non-linear projection operators and coarse constraints}
We define the convex sets on the fine level $K_J$ and on the coarser level $K_j$, for $j=J-1,...,1$, in the following way:
\begin{align}
\label{approximateconvexsets}
&K_J=\left\lbrace
  \bbx_J=(\bu_J, \bsigma_J) \in X_J: \quad \bu_J|_{\Gamma_D}=\bu_J^D , \:  \bsigma_J|_{\Gamma_N}=\bt_J^N, \: \bu_J\cdot \bn_J|_{\Gamma_C}\leq g_J, \: \bn^T(\bsigma_J \bn)  \leq 0, \: \bt_J^T(\bsigma \bn_J) =0
  \right\rbrace \\
&  K_j=\left\lbrace
  \bbx_j=(\bu_j, \bsigma_j) \in X_j: \quad \bu_j|_{\Gamma_D}=\textbf{0} , \:  \bsigma_j|_{\Gamma_N}=\textbf{0}, \: \bu_J\cdot \bn_j|_{\Gamma_C}\leq g_{j,u_n}, \: \bn^T(\bsigma_j \bn)  \leq g_{j,\sigma_n}, \: \bt_J^T(\bsigma \bn_J) =0
  \right\rbrace  \qquad 
\end{align}
The construction of a convex set $K_j$, for each level $j=1,...,J$, is a necessary step away from suboptimal complexity. Let $\bc_{j,\nu}=(\bu_{j,\nu},\bsigma_{j,\nu})$ be the correction at level $j$ on the vertex $\nu$. Furthermore let $ \bc_{J,0}= \bbx_J^k $, $ \bc_{j,0}= \textbf{0} $ for $j=J-1,...,1$ and $ \bw_{j,\nu}= \sum_{\mu=0}^{\nu}  \bc_{j,\mu}$ be respectively the current iterate, the first corrections on level $j$ and the sum of all the corrections on the same level $j$ until the vertex $\nu$. Unlike (\ref{exactlocalproblem}), we solve the following approximate local problem: successively find $\bc_{j,\nu} \in K_{j,\nu}(\bw_{j,\nu-1})$  and $  \bc_{1}  \in K_1 $ such that:
\begin{align}
\label{approximatelocalproblem}
\begin{split}
\mathcal{J}( \bw_{j,\nu-1}+\bc_{j,\nu}) &\leq \mathcal{J}( \bw_{j,\nu-1}+\by) \quad \forall \: \by \in K_{j,\nu}(\bw_{j,\nu-1})=\left\lbrace
\by \in \text{span}\{\lambda_{j,\nu}\}: \quad \by +\bw_{j,\nu-1} \in K_j
  \right\rbrace \quad j=J,...,2, \: \: \nu=1,...,N_j \\
  \mathcal{J}( \bc_{1})& \leq \mathcal{J}( \by) \quad   \qquad   \qquad
  \forall \: \by  \in K_1
  \end{split}
\end{align}
where, as opposed to (\ref{exactlocalconvexset}), in $K_{j,\nu}(\bw_{j,\nu-1})$ we consider $K_j$ instead of $K_J$. It is evident that, if $K_{j} \subset K_{j+1}$ for $j=1,...,J-1$, then $K_{j,\nu} \subset K_{j,\nu}^{*}$, which also implies that all the intermediate approximations of the solution belong to $K_J$. Therefore we must choose the coarse constraints function $ g_{j,u_n}$ and $ g_{j,\sigma_n}$ so that $K_j \subset K_{j+1}$. Of course $ g_{j,u_n}$ and $ g_{j,\sigma_n}$ will respectively depend on $ g_{j+1,u_n}$ and $ g_{j+1,\sigma_n}$ and, to this aim, specific projection operators need to be examined.\\
Let $j=H$, $j+1=h$. Then $\mathcal{T}_H=\mathcal{T}_j$ is a mesh at level $j$ and $\mathcal{T}_h=\mathcal{T}_{j+1}$ its uniform refinement. Given a coarse edge $\varepsilon_H \in \mathcal{E}_H \cap \Gamma_{C,H}$, which contains two coarse vertices $\nu_{H,1}$, $\nu_{H,2} \in \mathcal{N}_H$, on its ends, and a fine midpoint $\nu_h \in  \mathcal{N}_h$. Let $v_h \in U_{h,n} $ be a linear function defined on $\Gamma_{C,h}$. Its non-linear projection $v_H=I_h^H(v_h) \in U_{H,n}$ must fulfill $v_H \leq v_h$ and, consequently, $P_{H,n}^h v_H \leq v_h$, where $P_{H,n}^h$ is defined in (\ref{normalinterpolations}):
\begin{align}
\label{coarsegapfunctionconditionP1}
\begin{cases}
& v_H(p_{H,1}) \leq v_h(p_{H,1})\\
&  v_H(p_{H,2}) \leq v_h(p_{H,2})\\
&  \frac{1}{2}( v_H(p_{H,1}) + v_H(p_{H,2})) \leq v_h(p_{h})
\end{cases}
\quad \forall \varepsilon_H \in \mathcal{E}_H \cap \Gamma_{C,H}
\end{align}
It is easy to see that, on $e_H$, the two following values satisfy the three conditions above. 
\label{coarsegapfunctionconditionP1LinearInterpolation}
\begin{align}
\begin{cases}
v_H({p_{H,1}})= \min( v_h(p_{H,1}),\max( v_h(p_{h}), 2 v_h(p_{h}) - v_h(p_{H,2})) )\\
v_H({p_{H,2}})=\min( v_h(p_{H,2}),\max( v_h(p_{h}), 2 v_h(p_{h})- v_h(p_{H,1}) ) )
\end{cases}
\quad \forall \varepsilon_H \in \mathcal{E}_H \cap \Gamma_C
\end{align}
Anyhow, all the edges to which $\nu_{H,1}$ belongs need to be considered. Therefore the effect of the non linear interpolation $I_h^H$ can be summarized in this way: 
\begin{align}
\label{nonlinearprojectionun}
\displaystyle
&v_H=I_{h,u_n}^H v_h= \sum_{\nu_{H,i} \in \mathcal{N}_H \cap \Gamma_{C,H}} \left[\lambda_{U_H,H_i}\right]_n \:v_H(\nu_{H,i})
\quad \text{with} \quad
v_H(\nu_{H,1})= \min_{\varepsilon_H \in P_{\nu_{H,1}}^{E_H}} \left[ \min( v_h(\nu_{H,1}),\max( v_h(\nu_{h}), 2 v_h(\nu_{h}) - v_h(\nu_{H,2})) )  \right] 
\end{align}
Now consider a coarse face $\phi_H \in \mathcal{T}_H \cap \Gamma_{C,H}$ and fine faces which belong to it, i.e. $\phi_h \in P_{\phi_H}^{\phi_h}$. Then consider $s_h \in \Sigma_{h,n}$, a piecewise constant function on $\Gamma_{C,h}$. We want to define its non-linear projection $s_H=I_{h,\sigma_n}^H s_h \in \Sigma_{H,n}$ so that $s_H \leq s_h$ and $\Pi_{H,n}^h s_H \leq s_h$, where $\Pi_{H,n}^h$ is defined in (\ref{normalinterpolations}). It suffices that:
\begin{align*}
s_H(\phi_H) \leq s_h(\phi_h) \quad \forall \phi_h \in P_{\phi_H}^{\phi_h}
\end{align*}
Therefore:
\begin{align}
\label{nonlinearprojectionsigman}
\displaystyle
&s_H=I_{h,\sigma_n}^H s_h= \sum_{\phi_{H_i} \in T_H} \left[ \lambda_{\Sigma_H,H_i}\right]_n \:s_H(\phi_{H_i})
\quad \text{with} \quad
 s_H(\phi_{H_i})= \min_{\phi_{h} \in P_{\phi_{H_i}}^{\phi_{h}}} s_h(\phi_h)
\end{align}
Now that we have introduced the non-linear projections for both spaces, let $g \in U_{J,n}$ and $0 \in \Sigma_{J,n}$ be the fine constraints of the problem. Then, for each level $j=1,...,J$, we define coarse constraints $g_{j,u_n} \in U_{j,n}$, for the normal displacement corrections:
\begin{align}
\label{coarseconstraintun}
\begin{cases}
g_{J,u_n}=g & j=J \\
g_{j,u_n}=I_{j+1,u_n}^j \left( g_{j+1,u_n} - \sum_{\nu=1}^{N_{j+1}} \left[ \bu_{j+1,\nu} |_{\Gamma_C} \right]_n\right) & j=J-1,...,1
\end{cases}
\end{align}
and $g_{j,\sigma_n} \in \Sigma_{j,n}$, for the pressure corrections:
\begin{align}
\label{coarseconstraintsigman}
\begin{cases}
 g_{J,\sigma_n}=0 & j=J \\
g_{j,\sigma_n}=I_{j+1,\sigma_n}^j \left( g_{j+1,\sigma_n} - \sum_{\nu=1}^{N_{j+1}}  \left[ \bsigma_{j+1,\nu} |_{\Gamma_C}\right]_n \right) & j=J-1,...,1
\end{cases}
\end{align}
By exploiting (\ref{nonlinearprojectionun}), (\ref{nonlinearprojectionsigman}), (\ref{coarseconstraintun}), (\ref{coarseconstraintsigman}) and the definitions of the interpolation operators (\ref{interpolations}), it follows $K_j \subset K_{j+1}$ for $j=1,...,J-1$:
\begin{align*}
\sum_{\nu=1}^{N_{j}}  \left[ \bu_{j,\nu} |_{\Gamma_C}\right]_n \leq g_{g,u_n} 
\quad& \Rightarrow \quad
P_{j,n}^{j+1} \left(
\sum_{\nu=1}^{N_{j}} \left[  \bu_{j,\nu} |_{\Gamma_C}\right]_n\right) \leq g_{j+1,u_n}-
\sum_{\nu=1}^{N_{j+1}}  \left[ \bu_{j+1,\nu} |_{\Gamma_C}\right]_n\\
\sum_{\nu=1}^{N_{j}}  \left[ \bsigma_{j,\nu} |_{\Gamma_C}\right]_n \leq g_{j,\sigma_n} 
\quad &\Rightarrow \quad
\Pi_{j,n}^{j+1} \left(
\sum_{\nu=1}^{N_{j}}   \left[\bsigma_{j,\nu} |_{\Gamma_C}\right]_n\right) \leq g_{j+1,\sigma_n}-
\sum_{\nu=1}^{N_{j+1}}  \left[ \bsigma_{j+1,\nu}|_{\Gamma_C} \right]_n 
\end{align*}
Furthermore, by iterating the same argument for each level, it is clear that adding to the current iterate $\bbx^k+\sum_{j=1}^J \sum_{\nu}^{N_j }\bc_{j,\nu} \in K_J$:
\begin{align*}
\sum_{j=1}^{J-1}\:  \prod_{k=j}^{J-1}  P_{k,n}^{k+1}\left(
\sum_{\nu=1}^{N_{j}}   \left[\bu_{j,\nu}|_{\Gamma_C}\right]_n \right) +\left(
\sum_{\nu=1}^{N_{j+1}}  \left[\bu_{J,\nu}|_{\Gamma_C}\right]_n\right)
\leq g, \qquad
\sum_{j=1}^{J-1} 
\prod_{k=j}^{J-1} \Pi_{k,n}^{k+1} \left(
\sum_{\nu=1}^{N_{k}}  \left[ \bsigma_{k,\nu}|_{\Gamma_C} \right]_n\right) +\:
 \left(
\sum_{\nu=1}^{N_{J}}  \left[ \bsigma_{J,\nu}|_{\Gamma_C}   \right]_n \right)
 \leq 0
\end{align*}
${}$\\
By definition $g_{j,u_n}, g_{j,\sigma_n} \geq 0$. Therefore  it is clear that if at some level exists a $\nu_{j+1} \in \mathcal{N}_{j+1} \cap \Gamma_{C,j+1}$ or a $\phi_{j+1} \in \mathcal{F}_{j+1}\cap \Gamma_{C,j+1}$ such that:
\begin{align}
\label{nodesorfacesincontact}
g_{j+1,u_n}\big\rvert_{\nu_{j+1}} - \sum_{\nu=1}^{N_{j+1}} \left[ \bu_{j+1,\nu} \big\rvert_{\Gamma_C} \right]_n=0,\qquad\qquad
 g_{j+1,\sigma_n} \big\rvert_{\phi_{j+1}}-\sum_{\nu=1}^{N_{j+1}}  \left[ \bsigma_{j+1,\nu_{j+1}} \big\rvert_{\Gamma_C}\right]_n =0
\end{align}
the corresponding constraints on the successive coarser level j will be zero on all the nodes $\nu_j \in P_{\nu_{j+1}}^{\nu_j}$ or all the faces $\phi_j \in P_{\phi_{j+1}}^{\phi_j}$. Consequently no positive coarse correction in the direction of the obstacle can be expected there. And of course the same argument can be reproposed for each level $i=1,...,j-1$. Basically if (\ref{nodesorfacesincontact}) is satisfied, the coarser corrections that have one vertex $\nu_i$ or a face $\phi_i$, for $i<j$, belonging to $P_{\nu_{j+1}}^{\nu_i}$  or $P_{\phi_{j+1}}^{\phi_i}$ must be non positive. The implication of this fact is a slow down of the convergence, since we are not able to properly improve the solution in the obstacle direction. Truncated basis is the solution to this problem and has been already proposed in \cite{Kor94}. The idea is to consider the sets of basis functions as dependent on the current intermediate solution. The truncation comes into play in the transfer between levels. Such an operation is reflected in the matrix of the system on the level $j$ and in the standard interpolation operators $\bP_j^{j+1}$ and $\bPi_j^{j+1}$. In particular, all the degrees of freedom that satisfy (\ref{nodesorfacesincontact}) need to be switched off. Then the gap functions $g_{j,u_n}$, $g_{j,\sigma_n}$ can be defined in the usual way, except for the degrees of freedom where (\ref{nodesorfacesincontact}) is true. To this aim, before projecting onto the coarser level, we redefine:
\begin{align}
\label{nodesorfacesincontactinf}
g_{j+1,u_n}\big\rvert_{\nu_{j+1}} - \sum_{\nu=1}^{N_{j+1}} \left[ \bu_{j+1,\nu} \big\rvert_{\Gamma_C} \right]_n=+\infty,\qquad\qquad
 g_{j+1,\sigma_n} \big\rvert_{\phi_{j+1}}-\sum_{\nu=1}^{N_{j+1}}  \left[ \bsigma_{j+1,\nu_{j+1}} \big\rvert_{\Gamma_C}\right]_n =+\infty
\end{align}
so that all vertices and faces that fulfill equality constraints have no influence on coarser corrections.
\section{The minimization process}
\begin{algorithm}
\caption{\textbf{[x,WS]=NonLinearSmoothing(A,b,x,g,P,j,J,k)}}
\begin{algorithmic}
\State{$\bbx$=solution, $\textbf{WS}$=working set, $\bA$=system matrix, $\bb$=right hand side, $\bg=$ gap}  
\State{$\bP$=projections, $j$=level, $J$=maximum level, $k$=number of smoothing-steps }  
\State{TruncatedBasis: remove degrees of freedom belonging to the WorkingSet WS}
\State{CoarseConstraint: define $\bg_{j-1}$ such that $\bbx_{j}+\bP_{tr}\bbx_{j-1}\leq \bg_j $}
\State{}
     \If{  ($j=1$) }\\
\textbf{[x,WS]=ActiveSet(A,b,x,g)}
   \Else
\begin{enumerate}
\item \For{$\nu=1,...,\mathcal{N}_j$}
        \State $\bbx$=ActiveSet($A_{j,\nu}$, $\bb$)
      \EndFor 
\item Do $k$ non-linear smoothing-steps
\end{enumerate}   
    \EndIf 
  \end{algorithmic}
\end{algorithm}


\begin{algorithm}
\caption{\textbf{[x,WS]=V-CYCLE(A,b,x,g,P,j,J,k)}}
\begin{algorithmic}
\State{$\bbx$=solution, $\textbf{WS}$=working set, $\bA$=system matrix, $\bb$=right hand side, $\bg=$ gap}  
\State{$\bP$=projections, $j$=level, $J$=maximum level, $k$=number of smoothing-steps }  
\State{TruncatedBasis: remove degrees of freedom belonging to the WorkingSet WS}
\State{CoarseConstraint: define $\bg_{j-1}$ such that $\bbx_{j}+\bP_{tr}\bbx_{j-1}\leq \bg_j $}
\State{}
     \If{  ($j=1$) }\\
\textbf{[x,WS]=ActiveSet(A,b,x,g)}
   \Else
\begin{enumerate}
\item Do $k$ non-linear smoothing-steps: compute $\bbx$
\item Compute $ \bP_{tr} =\text{TruncatedBasis}(\bP,j,\textbf{WS}) $
\item Compute $\br_j=\bb-\bA \bbx$
\item Compute $\br_{j-1}=\bP_{tr}^T \br_j$
\item Compute $\textbf{G}_{j}=\bg_j-\bbx$
\item Compute $\bg_{j-1}=\text{CoarseConstraint}(\textbf{G}_{j})$
\item Compute $\bA_{j-1}=\bP_{tr}^T \bA_j \bP_{tr}^T$
\item \textbf{[x,WS]=V-CYCLE($\bA_{j-1},\br_{j-1}, \textbf{0} ,\bg_{j-1},\bP,j-1,J,k$)}
\item Do $k$ non-linear smoothing-steps
\end{enumerate}   
    \EndIf 
  \end{algorithmic}
\end{algorithm}





\bibliographystyle{plain} 
\bibliography{biblio}
%\end{thebibliography}{9}
\end{document}
