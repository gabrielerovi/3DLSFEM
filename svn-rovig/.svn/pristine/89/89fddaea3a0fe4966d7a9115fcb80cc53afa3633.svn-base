\documentclass[11pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
%\geometry{landscape}                		% Activate for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{amssymb}
\usepackage{amsmath}

%SetFonts

%SetFonts
\newcommand{\supp}{\operatorname{supp}}
\newcommand{\dist}{\operatorname{dist}}
\newcommand{\divr}{\operatorname{div}}
\newcommand{\ess}{\operatorname{ess}}
\newcommand{\rotore}{\operatorname{rot}}
\newcommand{\tr}{\operatorname{tr}}
\newcommand{\bA}{\textbf{A}}
\newcommand{\ba}{\textbf{a}}
\newcommand{\bb}{\textbf{b}}
\newcommand{\bB}{\textbf{B}}
\newcommand{\be}{\textbf{e}}
\newcommand{\bE}{\textbf{E}}
\newcommand{\bff}{\textbf{f}}
\newcommand{\bF}{\textbf{F}}
\newcommand{\bi}{\textbf{i}}
\newcommand{\bI}{\textbf{I}}
\newcommand{\bj}{\textbf{j}}
\newcommand{\bJ}{\textbf{J}}
\newcommand{\bm}{\textbf{m}}
\newcommand{\bM}{\textbf{M}}
\newcommand{\bn}{\textbf{n}}
\newcommand{\bN}{\textbf{N}}
\newcommand{\bp}{\textbf{p}}
\newcommand{\bP}{\textbf{P}}
\newcommand{\bo}{\textbf{o}}
\newcommand{\bq}{\textbf{q}}
\newcommand{\bQ}{\textbf{Q}}
\newcommand{\br}{\textbf{r}}
\newcommand{\bR}{\textbf{R}}
\newcommand{\btau}{\boldsymbol{\tau}}
\newcommand{\bt}{\textbf{t}}
\newcommand{\bv}{\textbf{v}}
\newcommand{\bV}{\textbf{V}}
\newcommand{\bw}{\textbf{w}}
\newcommand{\bW}{\textbf{W}}
\newcommand{\bu}{\textbf{u}}
\newcommand{\bU}{\textbf{U}}
\newcommand{\bbx}{\textbf{x}}
\newcommand{\bX}{\textbf{X}}
\newcommand{\beps}{\boldsymbol{\varepsilon}}
\newcommand{\bphi}{\boldsymbol{\phi}}
\newcommand{\bpsi}{\boldsymbol{\psi}}
\newcommand{\bomega}{\boldsymbol{\omega}}
\newcommand{\bsigma}{\boldsymbol{\sigma}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}
\newcommand{\bh}{\mathcal{H}}
\newcommand{\aaa}{\`a}
\newcommand{\eee}{\`e}
\newcommand{\iii}{\`i}
\newcommand{\ooo}{\`o}
\newcommand{\uuu}{\`u}
\newcommand{\aaaa}{\'a}
\newcommand{\eeee}{\'e}
\newcommand{\iiii}{\'i}
\newcommand{\oooo}{\'o}
\newcommand{\uuuu}{\'u}
\newcommand{\AAA}{\`A}
\newcommand{\EEE}{\`E}
\newcommand{\III}{\`I}
\newcommand{\OOO}{\`O}
\newcommand{\UUU}{\`U}
\newcommand{\AAAA}{\'A}
\newcommand{\EEEE}{\'E}
\newcommand{\IIII}{\'I}
\newcommand{\OOOO}{\'O}
\newcommand{\UUUU}{\'U}

\title{Signorini problem: adaptive least/squares }
\author{Gabriele Rovi}
%\date{}							% Activate to display a given date or no date


\begin{document}
\maketitle 
\section{Introduction}
\section{Contact boundary}
If the domain is locally Lipschitz, we can define local coordinates such that:
\begin{align*}
\gamma_{loc}=\{ (y_1,y_2,y_3): \: y_3 = \eta_{loc}(y_1,y_2), |y_1|<\alpha_1,\varepsilon, |y_2|<\alpha_2,\varepsilon, \varepsilon \:\:\varepsilon \text{sufficiently small}  \}
\end{align*}
So that locally we can represent the points : 
\begin{align*}
x_3 = \eta_x (x_1,x_2)
\end{align*}
Nota bene. Direi che il sistema locale di coordinate vede la "z" come la coordinata normale. \\
Sto dicendo che l'altezza (dall'alto) del punto spostato X deve essere inferiore a quella dell'ostacolo valutata nel punto spostato X. \\
ASSUNZIONE IMPLICITA: normali esterne sono tra loro vicine. Forse intende dire che se cosi non fosse, potrei avere un ostacolo con diverse concavita' e convessita', per cui nello spostare il punto, questo andrebbe a pentrare una protuberanza intermedia.
\begin{align*}
\eta_x(x_1,x_2)+u_3(x_1,x_2,\eta_x(x_1,x_2)) \leq \eta_y(x_1+u_1(x_1,x_2,\eta_x(x_1,x_2)),x_2+u_2(x_1,x_2,\eta_x(x_1,x_2)))
\end{align*}
Per piccoli spostamenti:
\begin{align*}
\eta_x(x_1,x_2)+u_3 \leq \eta_y(x_1,x_2)+\left( \dfrac{\partial \eta_y}{\partial y_1},\dfrac{\partial \eta}{\partial y_2}\right) \cdot \left(u_1,u_2\right)^T
\end{align*}
che porta a:
\begin{align*}
\bn_y \cdot (u_1,u_2,u_3)^T \leq G(x)
\end{align*}
dove la normale e' quella sull'ostacolo. Per piccoli spostamenti, la si confonde con quella del corpo.


\section{Poisson equation}
\begin{align*}
\begin{cases}
\bu+\nabla p=0\\
\text{div} \bu = f
\end{cases}
\end{align*}
\begin{align*}
\begin{cases}
\int_{\Omega}\bu \bv-\int_{\Omega}  p \text{div} \bv +\int_{\partial \Omega} p \bv \cdot \bn=0 \\ 
\int_{\Omega} \text{div} \bu  q= \int_{\Omega} f q\\
\end{cases}
\end{align*}
\begin{itemize}
\item $u_x$:
\begin{align*}
J(u_x,u_x)= \int \phi_u test_u  \qquad J(u_x,u_y)= 0 \quad J(u_x,p)=  -\int \phi_p test_{u,x}
\end{align*}
\item $u_y$:
\begin{align*}
J(u_y,u_x)= 0  \qquad J(u_y,u_y)= \int \phi_u test_u \quad J(u_y,p)=  - \int \phi_p test_{u,y}
\end{align*}
\item $p$:
\begin{align*}
J(p,u_x)= \int \phi_{u,x} test_p   \qquad J(p,u_y)= \int \phi_{u,y} test_p \quad J(p,p)=  0
\end{align*}
\end{itemize}
\section{Dual Linear Elasticity}
\begin{align*}
\begin{cases}
\mathcal{A} \bsigma - \boldsymbol{\varepsilon}(\bu)=0\\
\text{div} \bsigma + \bff=0
\end{cases}
\end{align*}
\begin{align*}
\begin{cases}
\int_{\Omega} \mathcal{A} \bsigma : \btau - \int_{\Omega}\boldsymbol{\varepsilon}(\bu): \btau=0\\
\int_{\Omega}  \left( \text{div} \bsigma + \bff \right) \bv=0
\end{cases}
\end{align*}
\begin{align*}
\begin{cases}
\int_{\Omega} \mathcal{A} \bsigma : \btau -\int_{\Omega}\nabla \bu : \frac{1}{2}(\btau+\btau^T)=0\\
\int_{\Omega}  \left( \text{div} \bsigma + \bff \right) \bv=0
\end{cases}
\end{align*}
\begin{align*}
\begin{cases}
\int_{\Omega} \mathcal{A} \bsigma : \btau +\frac{1}{2}\int_{\Omega} \bu\: \text{div}\left(\btau+\btau^T \right)- \frac{1}{2}\int_{\partial \Omega} \bu \cdot \left(\btau+\btau^T \right)\bn =0\\
\int_{\Omega}  \left( \text{div} \bsigma + \bff \right) \bv=0
\end{cases}
\end{align*}
In case the simmetry is strongly enforced in the space:
\begin{align*}
\begin{cases}
\int_{\Omega} \mathcal{A} \bsigma : \btau +\int_{\Omega} \bu\: \text{div}\btau- \int_{\partial \Omega} \bu \cdot \btau \bn =0\\
\int_{\Omega}  \left( \text{div} \bsigma + \bff \right) \bv=0
\end{cases}
\end{align*}
Being:
\begin{align*}
 \mathcal{A} \bsigma : \btau =  \beta \bsigma : \btau +  \alpha \text{tr}(\bsigma)\text{tr}(\btau) 
\end{align*}
\begin{itemize}
\item $\btau_{raw1}$:\\
\begin{align*}
\int_{\Omega}  \beta \bsigma_{raw1} \cdot \btau_{raw1} +  \alpha \left(\bsigma_{raw1,1}+\bsigma_{raw2,2} \right) \btau_{raw1,1}
+\int_{\Omega} \bu_1\: \text{div}\btau_{raw1}\\
\end{align*}
\item $\btau_{raw1}$:\\
\begin{align*}
\int_{\Omega}  \beta \bsigma_{raw2} \cdot \btau_{raw2} +  \alpha \left(\bsigma_{raw1,1}+\bsigma_{raw2,2} \right) \btau_{raw2,2}
+\int_{\Omega} \bu_2\: \text{div}\btau_{raw2}\\
\end{align*}
\item  $v_{1}$:\\
\begin{align*}
\int_{\Omega} \bv_1\: \text{div}\bsigma_{raw1}\\
\end{align*}
\item  $v_{2}$:\\
\begin{align*}
\int_{\Omega} \bv_2\: \text{div}\bsigma_{raw2}\\
\end{align*}
\end{itemize}
\section{LSFEM Linear Elasticity}
\begin{align*}
\begin{cases}
& -\left( \mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu), \boldsymbol{\varepsilon} (\bu_h ) \right)=0\\
&  \left( \text{div} \bsigma + \bff,  \text{div} \bsigma_h \right)
+ \left( \mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu), \mathcal{A} \bsigma_h \right)=0
\end{cases}
\end{align*}
We obtain the Jacobian:
\begin{itemize}
\item  $v_x$:\\
\begin{align*}
u_{x,x}v_{x,x} + \dfrac{u_{x,y}+u_{y,x}}{2} v_{x,y} + \beta \left(\sigma_{xx} v_{x,x} +\dfrac{\sigma_{xy}+\sigma_{yx}}{2} v_{x,y} \right)+\alpha \left(\sigma_{xx}+\sigma_{yy}\right) v_{x,x}
\end{align*}
\item  $v_y$:\\
\begin{align*}
u_{y,y}v_{y,y} + \dfrac{u_{x,y}+u_{y,x}}{2} v_{y,x} + \beta \left(\sigma_{yy} v_{y,y} +\dfrac{\sigma_{xy}+\sigma_{yx}}{2} v_{y,x} \right)+\alpha \left(\sigma_{xx}+\sigma_{yy}\right) v_{y,y}
\end{align*}
\item  $\tau_{raw,1}$:\\
\begin{align*}
\left( \text{div} \bsigma_{raw1} f_1\right) \text{div} \btau_{raw1} +
\beta^2 \bsigma_{raw1} \btau_{raw1} +
\tau_{raw1,1} \left( \sigma_{raw1,1} + \sigma_{raw2,2} \right)  \left( 2 \alpha \beta + \text{dim}\: \alpha^2 \right)\\
-\beta \left( u_{x,x} \tau_{raw1,1} +\dfrac{u_{x,y}+u_{y,x}}{2} \tau_{raw1,2} \right)
-\alpha \left( u_{x,x} +u_{y,y} \right) \tau_{raw1,1}
\end{align*}
\item  $\tau_{raw,2}$:\\
\begin{align*}
\left( \text{div} \bsigma_{raw2} f_2\right) \text{div} \btau_{raw2} +
\beta^2 \bsigma_{raw2} \btau_{raw2} +
\tau_{raw2,2} \left( \sigma_{raw1,1} + \sigma_{raw2,2} \right)  \left( 2 \alpha \beta + \text{dim}\: \alpha^2 \right)\\
-\beta \left( u_{y,y} \tau_{raw2,2} +\dfrac{u_{x,y}+u_{y,x}}{2} \tau_{raw2,1} \right)
-\alpha \left( u_{x,x} +u_{y,y} \right) \tau_{raw2,2}
\end{align*}
\end{itemize}

\subsection{Linear elasticity equations}

\section{Signorini problem: strong formulation}
\begin{align*}
\begin{cases}
\text{div} \bsigma + \bff=0 & \Omega  \qquad \text{momentum balance equation}\\
\mathcal{A} \bsigma - \boldsymbol{\varepsilon}(\bu)=0 &\Omega \qquad \text{constitutive law}\\
\bu = \bu^D & \Gamma_D\\
\bsigma \cdot \bn = \bt^N & \Gamma_N\\
\end{cases} 
\end{align*}
with the constraints:
\begin{align*}
\begin{cases}
\bu \cdot \bn - g  \leq 0 & \Gamma_D \qquad \text{impenetrability}\\
(\bsigma \bn) \cdot \bn \leq 0 &\Gamma_N \qquad \text{direction of the surface pressure}\\
\langle \bu \cdot \bn -g, (\bsigma \bn) \cdot \bn \rangle_{\Gamma_c}=0 & \Gamma_C \subset \Gamma_N \qquad \text{complementarity condition}
\end{cases}
\end{align*}
Between the two possible formulations, the one that uses $\mathcal{A} \bsigma -\boldsymbol{\varepsilon}=0$ is preferred to $\bsigma - \mathcal{C} \boldsymbol{\varepsilon}=0$. In this way, we can also deal with near incompressible or incompressible materials ($\lambda \gg 1$, $\lambda \to \infty$).
\begin{align*}
&\mathcal{A} \bsigma= \dfrac{1}{2 \mu} \left(\bsigma-\dfrac{\lambda}{d \lambda + 2 \mu } \text{tr} \bsigma \bI\right)\\
&\mathcal{C} \boldsymbol{\varepsilon}=\lambda \text{tr} \boldsymbol{\varepsilon}(\bu) \bI+ 2 \mu \boldsymbol{\varepsilon}(\bu)
\end{align*}


\section{Spaces}
\begin{align*}
&W^{m,p}(\Omega) =\{v \in L^p(\Omega) ; \quad \partial^{\alpha}  v \in L^p(\Omega) \quad \forall |\alpha| \leq m \}\\
&|| v ||_{m,p,\Omega}=\left( \sum_{|\alpha| \leq m \int_{\Omega} } | \partial^{\alpha} v(x) |^{\alpha} \right)^{1/p}
\end{align*}
where $W^{-m,p'}(\Omega)$, with $1/p+1/p'=1$ is the dual space normed by:
\begin{align*}
&|| f ||_{-m,p',\Omega}=\sup_{v \neq 0  v \in W_0^{m,p}(\Omega)} \dfrac{ \langle f, v \rangle }{|| v||_{m,p,\Omega} }
\end{align*}
A lemma characterizes the functionals of $W^{-m,p'}(\Omega)$:
\begin{align*}
f \in W^{-m,p'}(\Omega) \quad \iff \quad \exists  f_{\alpha}=  \sum_{|\alpha| \leq m  }| \partial^{\alpha} f_{\alpha}|\in L^{p'}(\Omega)  
\end{align*}
For $p=2$,  $W^{m,2}(\Omega)$ can be defined in a different way by using the Fourier transforms. For real $s >0$:
\begin{align*}
&H^{s}(\mathbb{R}^N) =\{v \in L^2(\mathbb{R}^N) ; \quad (1+|| x||^{2} )^{1/2}  \hat{v}(x) \in L^2(\mathbb{R}^N) \quad \forall |\alpha| \leq m \}\\
&|| v ||_{s,\mathbb{R}^N}=\left(|| v ||_{L^{2}(\mathbb{R} )}^{2} +|| (1+ || x||^{2} )^{s/2} \hat{v}(x)||_{L^{2}(\mathbb{R} )}^{2}  \right)^{1/2}\\
&H^{s}(\Omega) =\{ v \in L^2\: \quad \exists \tilde{v} \in H^{s}\left(\mathbb{R}^N\right) \:\: \text{with} \: \tilde{v} =v  \: \text{on} \:\Omega \}\\
&||v||_{s,\Omega} = \inf_{ \tilde{v} \in H^{s}\left(\mathbb{R}^N\right), \tilde{v} = v \: \text{in} \: \Omega} || \tilde{v}||_{s,\mathbb{R}^N}
\end{align*}
Let $\Omega$ be a Lipschitz-continuous bounded open subset of $\mathbb{R}^N$. Then:
\begin{align*}
&H^{s}(\Omega) = W^{s,2}\left(\Omega \right)
\end{align*}
\textbf{Theorem}\\
Let $\Omega$ be like in the previous definition (WHICH ONE) and let $p \geq 1$, $s \geq 0$ be two real numbers such that $s \leq  k + 1$, $s-1/p= l + \sigma$ where $l \geq 0$ is an integer and $\sigma < 1$. Then the mapping $ u \to \gamma_0 u$ defined on $\mathcal{D}(\bar{\Omega})$ has a unique linear continuous extension as an operator from: 
\begin{align*}
W^{s,p}\left(\Omega \right) \quad \text{onto} \quad W^{s-1/p,p}\left(\Gamma \right) 
\end{align*}
Moreover, in $W^{1,p}$ we have Ker$(\gamma_0)=W_0^{1,p}$. The norm that can be used is:
\begin{align*}
&||f||_{s-1/p,p,\Gamma} = 
\inf_{ \tilde{v} \in W^{s,p}\left(\Omega \right), \gamma_0 \tilde{v} = f \: \text{in} \: \Omega } 
|| \tilde{v}||_{s,p,\Omega}
\end{align*}

\begin{align*}
&H_d^1(\Omega) = \{q \in H^1 \left(\Omega \right): \:q=0 \:\text{on}\:\Gamma_d \}\\ 
&H_d^1(\text{div},\Omega) = \{\bw \in H^1 \left(\text{div},\Omega \right): \: \bw \cdot \bn=0 \:\text{on}\:\Gamma_N \}\\
&V_h \subset H_d^1(\Omega)\\
&\Sigma_h \subset H_d^1(\text{div},\Omega)\\
&H_d^{1/2}(\Gamma_d) = \{v \in L^2 \left(\Gamma_d \right): \: \exists u \in H_d^1(\Omega), \:v=\text{tr} (u) \}\\ 
&H_d^{-1/2}(\Gamma_N) \: \: \qquad H_d^{1/2}(\Gamma_N)  \text{ dual space}\\  
&|| f ||_{-1/2,\Omega}=\sup_{v \neq 0 , \: v \in W_0^{1/2}(\Omega)} \dfrac{ \langle f, v \rangle }{|| v||_{1/2,\Omega} }
\end{align*}



\section{Least squares functionals}
The least squares functional:
\begin{align*}
\mathcal{F}_C(\bu,\bsigma)=||\text{div} \bsigma+\bff||^2+||\mathcal{A}\bsigma -\boldsymbol{\varepsilon}(\bu)||^2 \geq 0
\end{align*}
and the augmented least squares functional (positive thanks to the constraints):
\begin{align*}
\mathcal{F}(\bu,\bsigma)=||\text{div} \bsigma+\bff||^2+||\mathcal{A}\bsigma -\boldsymbol{\varepsilon}(\bu)||^2+\langle \bu \cdot \bn, (\bsigma \bn) \cdot \bn \rangle_{\Gamma_C} \geq 0  
\end{align*}
Searching for an approximate solution $(\bu_h^{\perp},\bsigma_h^{\perp})$ such that exactly satisfy:
\begin{align*}
\langle \bu \cdot \bn, (\bsigma \bn) \cdot \bn \rangle_{\Gamma_C}=0
\end{align*}
means that (being the set of $(\bu_h^{\perp},\bsigma_h^{\perp})$ smaller than the one in which we search for $(\bu_h^{},\bsigma_h^{})$):
\begin{align*}
\mathcal{F}(\bu_h,\bsigma_h) \leq \mathcal{F}_C(\bu_h,\bsigma_h) \leq \mathcal{F}_C(\bu_h^{\perp},\bsigma_h^{\perp}) =\mathcal{F}(\bu_h^{\perp},\bsigma_h^{\perp}) 
\end{align*}


\section{Solving the functional}
We have to minimize the augmented functional:
\begin{align*}
\mathcal{F}_C(\bu,\bsigma)=||\text{div} \bsigma+\bff||^2+||\mathcal{A}\bsigma -\boldsymbol{\varepsilon}(\bu)||^2+\langle \bu \cdot \bn, (\bsigma \bn) \cdot \bn \rangle_{\Gamma_C} \geq 0  
\end{align*}
with respect to the finite element subspaces $V_h \subset  H_d^1(\Omega)^d $ and $\Sigma_h \subset H_{N,C}(\text{div},\Omega)$. So we search for a solution $(\bu_h,\bsigma_h) = (\bu^D,\bsigma^N)+(\hat{\bu}_h,\hat{\bsigma}_h) $ with $\hat{\bu}_h$ and $\hat{\bsigma}$ in $V_h$ and $\Sigma_h$, such that the inequality constraints are satisfied. \\
This is equivalent to the system of variational inequalities:
\begin{align}
\begin{cases}
-2 \left( \mathcal{A} \bsigma_h-\boldsymbol{\varepsilon}(\bu_h),\boldsymbol{\varepsilon}(\bv_h-\bu_h) \right)+
\langle \bn \cdot (\bsigma_h  \bn), \bn \cdot (\bv_h-\bu_h)\rangle_{\Gamma_C} \geq 0\\
2 \left( \text{div} \bsigma_h + \bff, \text{div} (\btau_h-\bsigma_h)\right)+
2\left( \mathcal{A} \bsigma_h - \boldsymbol{\varepsilon}(\bu_h), \mathcal{A}(\btau_h-\bsigma_h \right)+
\langle \bn \cdot \bu_h  -g, \bn \cdot (\btau_h-\bsigma_h)\rangle_{\Gamma_C} \geq 0\\
\end{cases}
\end{align}


\section{A posteriori error estimator}
\textbf{Theorem}\\
Let $(\bu_h,\bsigma_h) \in H^1(\Omega)^d \times H(\text{div},\Omega)^d$ be the exact solution of the constrainted problem. Then $\forall (\bu_h,\bsigma_h) \in (\bu_h^D,\bsigma_h^D)  + V_h \times \Sigma_h$ which satisfy the constraints, $\exists \: C_R>0$ ($\lambda$ indipendent) such that:
\begin{align*}
&\mathcal{F}_C(\bu,_h\bsigma_h) \geq C_R
\left(|| (\boldsymbol{\varepsilon}(\bu_h)-\boldsymbol{\varepsilon}(\bu))||^2+||\text{div} (\bsigma-\bsigma_h)||^2+||\mathcal{A}(\bsigma-\bsigma_h)||^2 \right)  
\end{align*}

\textbf{Korn's inequality}\\
Let $\Gamma_d \subset \Gamma$ be a set of positive measure $|\Gamma_d| > 0$. Then $|| \boldsymbol{\varepsilon}\left( \bv \right)||$ is an equivalent norm to $||v||_{1,\Omega} $ in $H_d^1(\Omega)^d$
\begin{align*}
&||v||_{1,\Omega} \leq C_l || \boldsymbol{\varepsilon}\left( \bv \right)|| \qquad \forall \bv \in H_d^1(\Omega)^d
\end{align*}
\textbf{Lemma 1}\\
Let $\Gamma_N \subset \Gamma$ be a set of positive measure $|\Gamma_N| > 0$. Then:
\begin{itemize}
\item \begin{align*}
|| \btau|| \leq C \left( ||\text{dev} (\btau)||+|| \text{div} (\btau) || \right) \qquad
 \forall \btau \in H_N(\text{div}, \Omega)^d
\end{align*}
\item \begin{align*}
|| \text{dev} \btau|| \leq 2 \mu  ||\mathcal{A} (\btau) ||  \qquad
|| \text{dev} \btau|| \leq  \sqrt{2 \mu}  \left( \mathcal{A} (\btau),\btau \right) 
\end{align*}
\item Trace inequalities: \begin{align*}
||v||_{1/2,\Gamma_C} \leq C_T \mu  ||v||_{1,\Omega} \quad \forall \: \bv \in H^1(\Omega) \qquad  \qquad
|| \bsigma \cdot \bn||_{-1/2,\Gamma_c} \leq  C_T || \bsigma||_{\text{div},\Omega} \quad \forall \: \bsigma  \in H_N(\text{div},\Omega)
\end{align*}
\end{itemize}
\begin{align*}
&\mathcal{F}(\bu,\bsigma)=||\text{div} \bsigma + \bff||^2 + || \mathcal{A} \bsigma-\boldsymbol{\varepsilon}(\bu)||^2\\
&\mathcal{F}_C(\bu,\bsigma)=||\text{div} \bsigma + \bff||^2 + || \mathcal{A} \bsigma-\boldsymbol{\varepsilon}(\bu)||^2+ \langle \bn \cdot \bu -g, \bn \cdot (\bsigma \cdot \bn)\rangle
\end{align*}


\section{The least squares functional as an a posteriori estimator: reliability and efficiency}
Let be $e$ the error. Then we want a functional that is both reliable and efficient. In this way, the functional is equivalent to the norm of the error.
\begin{align}
&C_1 ||\text{e}||  \overbrace{\leq}^{ \text{reliability} }  \mathcal{F} \overbrace{\leq}^{\text{efficiency}} C_2 ||\text{e}||  \qquad \to \qquad
 ||\text{e}||   \to 0 \qquad \iff \qquad \mathcal{F} \to 0
\end{align}
If both are taken singularly, we are no sure of the fact that the functional is a good estimator. Indeed it could happen:\\
Reliability: $||\text{e}|| \approx 0$, $\mathcal{F} \gg 1$ (refinement, although is not necessary $\to$ wasting time)\\
Efficiency:     $\mathcal{F} \approx 0$, $||\text{e}|| \gg 1$ (not refinement, but it is necessary $\to$ bad solving) 


\subsection{Reliability}
$(\bu_h,\bsigma_h) \in (\bu^D,\bsigma^N)+\bV_h \times \bSigma_h$.
\begin{align*}
&\mathcal{F}_C(\bu_h,\bsigma_h) \geq C_R \left( 
\overbrace{||\text{div}(\bsigma-\bsigma_h)||^2}^{a)}+
\overbrace{||\mathcal{A}(\bsigma-\bsigma_h)||^2}^{b)}+
\overbrace{|| \boldsymbol{\varepsilon}(\bu-\bu_h)||^2}^{c)}
 \right)
\end{align*}


\begin{itemize}
\item a)  \begin{align*}
 ||\text{div}(\bsigma-\bsigma_h)||^2\overset{\pm \bff}{=}||\text{div}(\bff+\bsigma_h)||^2 \leq \mathcal{F}_C(\bu_h,\bsigma_h)
\end{align*}
\item b) Remarking the fact that, for a scalar product, $(\text{sym}(a),b)+(a,\text{as}(b))=(a,b)$ and using Greens formula:
\begin{align*}
(\boldsymbol{\varepsilon}(\bu-\bu_h),\bsigma-\bsigma_h)=&
\langle (\bsigma-\bsigma_h)\cdot \bn , \bu -\bu_h\rangle_{\Gamma_C}-(\text{div}(\bsigma-\bsigma_h),\bu-\bu_h)-(\text{as}(\bsigma-\bsigma_h),\nabla(\bu-\bu_h))\\
\overset{\text{lemma1}}{\leq} &\langle \bsigma_h \bn \cdot  \bn , \bu_h \cdot \bn -g\rangle_{\Gamma_C}+\\
&||\text{div} (\bsigma- \bsigma_h)|| ||\bu- \bu_h||+||\text{as} (\bsigma- \bsigma_h)|| ||\nabla(\bu- \bu_h)||\\
{\leq} &\mathcal{F}_C(\bu_h,\bsigma_h)+ \sqrt{2} \left(
||\text{div} (\bsigma- \bsigma_h)||^{2}+||\text{as} (\bsigma- \bsigma_h)||^{2} \right)^{1/2}||\bu- \bu_h||_1
\end{align*}
where:
\begin{align*}
||\text{div} (\bsigma- \bsigma_h)||^{2}+||\text{as} (\bsigma- \bsigma_h)||^{2} \overset{\text{as}(\bsigma)=0}{=} &||\text{div} (\bsigma_h)+\bff||^{2}+||\text{as} ( \bsigma_h)||^{2}\\
\overset{\text{as}(\boldsymbol{\varepsilon}(\bu_h))=0}{=}& ||\text{div} (\bsigma_h)+\bff||^{2}+(2 \mu)^{2}||\text{as} (\mathcal{A} \bsigma_h-\boldsymbol{\varepsilon}(\bu_h))||^{2}\\
\overset{ ||\text{as}(\cdot)||\leq  ||\text{}(\cdot)||}{=}& ||\text{div} (\bsigma_h)+\bff||^{2}+(2 \mu)^{2}|| (\mathcal{A} \bsigma_h-\boldsymbol{\varepsilon}(\bu_h))||^{2}\\
\leq & \max(1, (2 \mu)^{2})\mathcal{F}_C(\bu_h,\bsigma_h)
\end{align*}
Now we take advantage of this inequality:
\begin{align*}
||\boldsymbol{\varepsilon} (\bu_h- \bu)|| \overset{\pm \mathcal{A} \bsigma}{=} &|| ( \mathcal{A} \bsigma -\boldsymbol{\varepsilon} (\bu) ) + (\boldsymbol{\varepsilon} (\bu_h) - \mathcal{A} \bsigma)||=\\
 \overset{ \mathcal{A} \bsigma -\boldsymbol{\varepsilon} (\bu) = 0 }{=} & ||\boldsymbol{\varepsilon} (\bu_h) - \mathcal{A} \bsigma||\\
   \overset{ \pm \mathcal{A} \bsigma_h} {\leq}   &||\mathcal{A}\bsigma- \mathcal{A} \bsigma_h||_1+||\boldsymbol{\varepsilon} (\bu_h) - \mathcal{A} \bsigma_h||\\
{\leq}     &||\mathcal{A}\bsigma- \mathcal{A} \bsigma_h||+ \mathcal{F}_C(\bu_h,\bsigma_h)^{1/2}
\end{align*}
and using the Korn's inequality:
\begin{align*}
(\boldsymbol{\varepsilon}(\bu-\bu_h),\bsigma-\bsigma_h) \leq & \mathcal{F}_C(\bu_h,\bsigma_h) +  \sqrt{2 \max(1, (2 \mu)^{2})}  \mathcal{F}_C(\bu_h,\bsigma_h)^{1/2} ||\boldsymbol{\varepsilon} (\bu- \bu_h)||\\
{\leq}  & C \mathcal{F}_C(\bu_h,\bsigma_h)^{1/2} ( \mathcal{F}_C(\bu_h,\bsigma_h)^{1/2}+||\mathcal{A}\bsigma- \mathcal{A} \bsigma_h||)\\
 &\overset{ ||\bsigma- \bsigma_h||_{\mathcal{A}} =(\mathcal{A}\bsigma,\bsigma)} {\leq}   C \mathcal{F}_C(\bu_h,\bsigma_h)^{1/2} ( \mathcal{F}_C(\bu_h,\bsigma_h)^{1/2}+||\bsigma- \bsigma_h||_{\mathcal{A}})
\end{align*}
where the last inequality holds with a particular C indipendent on $\lambda$:
\begin{align*}
(\mathcal{A} \bsigma, \bsigma)=& \int_{\Omega} \dfrac{1}{2 \mu}\left[  \sum_{i \neq j} \sigma_{ij}^{2}  + \sum_{i = j} (\sigma_{ij}-\text{tr}\sigma_{ij})\sigma_{ij} \right]+\dfrac{1}{d(d \lambda + 2 \mu)}\left[ \sum_{i = j} \sigma_{ij}\text{tr}  \sigma_{ij} \right]=\\
&\int_{\Omega} \dfrac{1}{2 \mu}\left[  \sum_{i, j} \sigma_{ij}^{2}  - \text{tr} ^{2} \sigma_{ij} \right]+\dfrac{1}{d(d \lambda + 2 \mu)} \text{tr} ^{2} \sigma_{ij}=\\
&\int_{\Omega} \dfrac{1}{2 \mu}  \left[\sum_{i, j} \sigma_{ij}^{2}  +\dfrac{ 2(d-1) \mu+ \lambda d^{2} }{2 \mu d(d \lambda + 2 \mu)} \text{tr}^{2} \sigma_{ij} \right]\\
(\mathcal{A} \bsigma, \mathcal{A} \bsigma)=& \int_{\Omega} \left(\dfrac{1}{2 \mu}\right)^{2} \left[  \sum_{i \neq j} \sigma_{ij}^{2}  + \sum_{i = j} (\sigma_{ij}-\text{tr}\sigma_{ij})^{2}\right]+\dfrac{1}{d(d \lambda + 2 \mu)^{2}}  \text{tr}^{2}\sigma_{ij} \\
& \int_{\Omega} \left(\dfrac{1}{2 \mu}\right)^{2} \left[  \sum_{i, j} \sigma_{ij}^{2}  + \dfrac{(2 \mu)^{2} + (d-2)d (d \lambda + 2 \mu)^{2}}{d(d \lambda + 2 \mu)^{2}}  \text{tr}^{2}\sigma_{ij} \right]\\
\end{align*}
where the costant $C$ can be defined as:
\begin{align*}
C=\dfrac{1}{2 \mu} \sup_{\lambda} \left[1, 
\left(\dfrac{2 \mu d(d \lambda + 2 \mu)} { 2(d-1) \mu+ \lambda d^{2} }\right) 
\left(\dfrac{(2 \mu)^{2} + (d-2)d (d \lambda + 2 \mu)^{2}}{d(d \lambda + 2 \mu)^{2}}  \right)\right]
\end{align*}
Therefore:
\begin{align*}
||\bsigma -\bsigma_h||_{\mathcal{A}}^{2} \overset{\pm \boldsymbol{\varepsilon}(\bu-\bu_h)}{=}&(\mathcal{A}(\bsigma-\bsigma_h)-\boldsymbol{\varepsilon}(\bu-\bu_h), \bsigma-\bsigma_h)+(\boldsymbol{\varepsilon}(\bu-\bu_h),\bsigma-\bsigma_h)\\
\leq &  \sqrt{2} (||\mathcal{A}(\bsigma-\bsigma_h)||^{2}  +  ||\boldsymbol{\varepsilon}(\bu-\bu_h)||^{2})^{1/2}     ||\bsigma -\bsigma_h||+\\ 
&C \mathcal{F}_C(\bu_h,\bsigma_h)^{1/2}(\mathcal{F}_C(\bu_h,\bsigma_h)^{1/2}+||\bsigma -\bsigma_h||_{\mathcal{A}})\\
\leq & \mathcal{F}_C(\bu_h,\bsigma_h)^{1/2}||\bsigma -\bsigma_h||+ C \mathcal{F}_C(\bu_h,\bsigma_h)^{1/2}(\mathcal{F}_C(\bu_h,\bsigma_h)^{1/2}+||\bsigma -\bsigma_h||_{\mathcal{A}})
\end{align*}
Now by using the lemma 2:
\begin{align*}
 ||\bsigma -\bsigma_h|| \leq &\tilde{C}_D ( (\mathcal{A}(\bsigma -\bsigma_h),(\bsigma -\bsigma_h)) + || \text{div} (\bsigma -\bsigma_h) ||)\\
  = & \tilde{C}_D (||\bsigma -\bsigma_h||_{\mathcal{A}} + || \text{div} (\bff +\bsigma_h) ||)\\
  \leq & \tilde{C}_D (||\bsigma -\bsigma_h||_{\mathcal{A}} + \mathcal{F}(\bu_h,\bsigma_h))^{1/2}
\end{align*}
So finally:
\begin{align*}
||\bsigma -\bsigma_h||_{\mathcal{A}}^{2} \leq C \mathcal{F}_C(\bu_h,\bsigma_h)^{1/2} \left( \mathcal{F}_C(\bu_h,\bsigma_h)^{1/2}+||\bsigma -\bsigma_h||_{\mathcal{A}}) \right)
\end{align*}
Then exists a constant $C_R$ such that:
\begin{align*}
C_R ||\bsigma -\bsigma_h||_{\mathcal{A}}^{2} \leq \mathcal{F}(\bu_h,\bsigma_h)
\end{align*}
Imposing $||\bsigma -\bsigma_h||_{\mathcal{A}}=x$ and ${\mathcal{F}}(\bu_h,\bsigma_h)= {C_R} x^{2} $, we obtain $x^{2} \leq C {C_R} x^{2} +C {C_R} x^{2} $ and find that $C_R \geq \dfrac{1}{2 C}$. Even more so, we can state that:
\begin{align*}
C_R ||{\mathcal{A}}(\bsigma -\bsigma_h)||^{2} \leq \mathcal{F}(\bu_h,\bsigma_h)
\end{align*}
\item c) Taking advantage of the previous point:
\begin{align*}
 ||\boldsymbol{\varepsilon}(\bu-\bu_h)||= &||\mathcal{A}(\bsigma-\bsigma_h)+\mathcal{A}(\bsigma_h)-\boldsymbol{\varepsilon}(\bu_h)||=\\
 \leq & ||\mathcal{A}(\bsigma-\bsigma_h)||+||\mathcal{A}(\bsigma_h)-\boldsymbol{\varepsilon}(\bu_h)||\\
  \leq & ||\mathcal{A}(\bsigma-\bsigma_h)||+\mathcal{F}(\bu_h,\bsigma_h)^{1/2}\\
  \leq & \left( \dfrac{1}{C_R}+1 \right) \mathcal{F}(\bu_h,\bsigma_h)^{1/2}
\end{align*}
\end{itemize}





\section{Efficiency}
The element-wise version of the augmented functional:
\begin{align*}
\mathcal{F}_{C,T}(\bu,\bsigma)&=\mathcal{F}_{T}(\bu,\bsigma)+\langle \bu \cdot \bn, (\bsigma \bn) \cdot \bn \rangle_{\Gamma_C \cap \delta T}\\
&=||\text{div} \bsigma+\bff||_T^2+||\mathcal{A}\bsigma -\boldsymbol{\varepsilon}(\bu)||_T^2+\langle \bu \cdot \bn, (\bsigma \bn) \cdot \bn \rangle_{\Gamma_C \cap \delta T}
\end{align*}
We can minimize $\mathcal{F}_T$ as follows:
\begin{align*}
\mathcal{F}_{T}(\bu_h,\bsigma_h) 
&\overset{\mathcal{A} \bsigma - \boldsymbol{\varepsilon}(\bu)=0 }{=} 
||\text{div} \bsigma_h+\bff \pm \bsigma||_T^2+||(\mathcal{A}\bsigma -\boldsymbol{\varepsilon}(\bu) )+(\boldsymbol{\varepsilon}(\bu_h)-\mathcal{A}\bsigma_h)||_T^2\\
& \overset{\text{div} \bsigma + \bff=0} {\leq}||\text{div} (\bsigma- \bsigma_h)||_T^2+ 2||\mathcal{A}(\bsigma-\bsigma_h) ||_T^2 +2||(\boldsymbol{\varepsilon}(\bu-\bu_h)||_T^2\\
& \quad \:\:\:{\leq} 2\:\:\left(||\text{div}( \bsigma- \bsigma_h)||_T^2+ ||\mathcal{A}(\bsigma-\bsigma_h) ||_T^2 +||(\boldsymbol{\varepsilon}(\bu-\bu_h)||_T^2\right)
\end{align*}
Regarding the boundary term, we take advantage of the following fact:
\begin{align*}
\begin{cases}
\Gamma_{C,a},\: \:\bu \cdot \bn - g=0: &\langle \bu_h \cdot \bn-g, (\bsigma_h \bn) \cdot \bn \rangle_{\Gamma_{C,a}} =\langle  (\bu_h-\bu)\cdot \bn, ((\bsigma_h-\bsigma) \bn) \cdot \bn \rangle_{\Gamma_{C,a}} \\
\Gamma_C \backslash \Gamma_{C,a} ,\:      (\bsigma \bn) \cdot \bn =0: & \langle \bu_h \cdot \bn-g, (\bsigma_h \bn) \cdot \bn \rangle_{\Gamma_C \backslash \Gamma_{C,a}} =\langle \bu_h \cdot \bn-g, ((\bsigma_h -\bsigma_h)\bn) \cdot \bn \rangle_{\Gamma_C \backslash \Gamma_{C,a}}
\end{cases}
\end{align*}
in order to show that:
\begin{align*}
\langle \bu_h \cdot \bn-g, (\bsigma_h \bn) \cdot \bn \rangle_{\Gamma_C }
=&\langle \bu_h \cdot \bn-g, (\bsigma_h \bn) \cdot \bn \rangle_{\Gamma_C \backslash \Gamma_{C,a} }+\langle \bu_h \cdot \bn-g, (\bsigma_h \bn) \cdot \bn \rangle_{\Gamma_{C,a}}\\
=&\langle \bu_h \cdot \bn-g \pm \bu \cdot \bn, ((\bsigma_h -\bsigma)\bn) \cdot \bn \rangle_{\Gamma_C \backslash \Gamma_{C,a}}+\langle  (\bu_h-\bu)\cdot \bn, ((\bsigma_h \pm \bsigma) \bn) \cdot \bn \rangle_{\Gamma_{C,a}} \\
=&\langle \bu\cdot \bn-g, ((\bsigma_h -\bsigma)\bn) \cdot \bn \rangle_{\Gamma_C \backslash \Gamma_{C,a}}+\langle  (\bu_h-\bu)\cdot \bn, (\bsigma \bn) \cdot \bn \rangle_{\Gamma_{C,a}}+\\
&\langle  (\bu_h-\bu)\cdot \bn, ((\bsigma_h-\bsigma) \bn) \cdot \bn \rangle_{\Gamma_{C}} \\
=&\langle \bu\cdot \bn-g, ((\bsigma_h -\bsigma_h)\bn) \cdot \bn \rangle_{\Gamma_C }+\langle  (\bu_h-\bu)\cdot \bn, (\bsigma \bn) \cdot \bn \rangle_{\Gamma_{C}}+\\
&\langle  (\bu_h-\bu)\cdot \bn, ((\bsigma_h-\bsigma) \bn) \cdot \bn \rangle_{\Gamma_{C}} \\
\end{align*}
Using Cauchy-Schwarz and trace inequalities:
\begin{align*}
\langle \bu_h \cdot \bn-g, (\bsigma_h \bn) \cdot \bn \rangle_{\Gamma_C }
=&\langle \bu\cdot \bn-g, ((\bsigma_h -\bsigma_h)\bn) \cdot \bn \rangle_{\Gamma_C }+\langle  (\bu_h-\bu)\cdot \bn, (\bsigma \bn) \cdot \bn \rangle_{\Gamma_{C}}+\\
&\langle  (\bu_h-\bu)\cdot \bn, ((\bsigma_h-\bsigma) \bn) \cdot \bn \rangle_{\Gamma_{C}} \\
\leq &||\bu \cdot \bn-g||_{1/2,\Gamma_C}||(\bsigma_h-\bsigma) \bn||_{-1/2,\Gamma_C}+
||\bu_h-\bu||_{1/2,\Gamma_C}||\bsigma \bn||_{-1/2,\Gamma_C}+\\
&||\bu_h-\bu||_{1/2,\Gamma_C}||(\bsigma_h-\bsigma) \bn||_{-1/2,\Gamma_C}\\
\overset{}{\leq} &C_T||\bu \cdot \bn-g||_{1/2,\Gamma_C}||(\bsigma_h-\bsigma) \bn||_{1,\Omega}+
C_T||\bu_h-\bu||_{1,\Omega}||\bsigma \bn||_{-1/2,\Gamma_C}+\\
& C_T^2 ||\bu_h-\bu||_{1,\Omega}||(\bsigma_h-\bsigma) \bn||_{1,\Omega}
\end{align*}
We cannot rule out that the contact boundary term converges at a slower rate than the error itself.
So we could avoid the presence of this term. Let the least squares functional be:
\begin{align*}
\mathcal{F}_C(\bu,\bsigma)=||\text{div} \bsigma+\bff||^2+||\mathcal{A}\bsigma -\boldsymbol{\varepsilon}(\bu)||^2 \geq 0
\end{align*}
and the augmented least squares functional (positive thanks to the constraints) be:
\begin{align*}
\mathcal{F}(\bu,\bsigma)=||\text{div} \bsigma+\bff||^2+||\mathcal{A}\bsigma -\boldsymbol{\varepsilon}(\bu)||^2+\langle \bu \cdot \bn, (\bsigma \bn) \cdot \bn \rangle_{\Gamma_C} \geq 0  
\end{align*}
Searching for an approximate solution $(\bu_h^{\perp},\bsigma_h^{\perp})$ such that exactly satisfy:
\begin{align*}
\langle \bu \cdot \bn, (\bsigma \bn) \cdot \bn \rangle_{\Gamma_C}=0
\end{align*}
means that (being the set of $(\bu_h^{\perp},\bsigma_h^{\perp})$ smaller than the one in which we search for $(\bu_h^{},\bsigma_h^{})$):
\begin{align*}
\mathcal{F}(\bu_h,\bsigma_h) \leq \mathcal{F}_C(\bu_h,\bsigma_h) \leq \mathcal{F}_C(\bu_h^{\perp},\bsigma_h^{\perp}) =\mathcal{F}(\bu_h^{\perp},\bsigma_h^{\perp}) 
\end{align*}
Namely, this solution $(\bu_h^{\perp},\bsigma_h^{\perp})$ is worse than $(\bu_h,\bsigma_h)$, but converges more quickly. However in practical cases, the boundary contribution is not so relevant with respect to the whole domain one, so we can search for $(\bu_h,\bsigma_h)$.

\textbf{Lemma 1}\\
Let $(\bu,\bsigma) \in H^1(\Omega)^2 \times H(\text{div},\Omega)^d$ be the exact solution of the contact problem. Moreover, let $(\bu_h,\bsigma_h) \in (u^D+\bU_h) \times \Sigma_h$ be such that the constraints are satisfied. Then:
\begin{align*}
\langle \bu-\bu_h,(\bsigma-\bsigma_h) \bn \rangle_{\Gamma_c}=\langle (\bu-\bu_h) \cdot \bn,(\bsigma-\bsigma_h)\bn \cdot \bn \rangle_{\Gamma_c} \leq 
\langle \bn \cdot \bu_h-g, \bsigma_h \bn \cdot \bn\rangle_{\Gamma_c}
\end{align*}

\textbf{Proof}\\
\begin{align*}
\begin{cases}
\Gamma = \Gamma_{c,d} \cup \Gamma_{c,s}\\
\bn \cdot \bu - g \leq 0 &\Gamma_c\\
(\bsigma \bn) \cdot \bn \leq 0 &\Gamma_c\\
\bu \cdot \bn - g=0 & \Gamma_{c,d}\\
(\bsigma \bn) \cdot \bn =0 & \Gamma_{c,s} 
\end{cases}
\quad \to \quad
\begin{cases}
\langle \bn \cdot \bu_h-g, \bsigma \bn \cdot \bn\rangle_{\Gamma_c,d} \geq 0\\
\langle \bn \cdot \bu-g, \bsigma_h \bn \cdot \bn\rangle_{\Gamma_c,s} \geq 0 
\end{cases}
\end{align*}
Therefore:
\begin{align*}
\langle \bn \cdot \bu_h-g,& (\bsigma_h \bn) \cdot \bn\rangle_{\Gamma_c} \geq\\
&\langle \bn \cdot \bu_h-g, ((\bsigma_h-\bsigma) \bn) \cdot \bn\rangle_{\Gamma_{c,d}}+\langle \bn \cdot (\bu_h-\bu), (\bsigma_h \bn) \cdot \bn\rangle_{\Gamma_{c,s}} = \\
&\langle \bn \cdot (\bu_h-\bu), ((\bsigma_h-\bsigma) \bn) \cdot \bn\rangle_{\Gamma_{c,d}}+
\langle \bn \cdot (\bu_h-\bu), (\bsigma_h-\bsigma \bn) \cdot \bn\rangle_{\Gamma_{c,s}} = \\
&\langle \bn \cdot (\bu_h-\bu), ((\bsigma_h-\bsigma) \bn) \cdot \bn\rangle_{\Gamma_c}
\end{align*}
\textbf{Lemma 2}\\
Let be $\Gamma_N$ be a set of positive measure, $|\Gamma_N|>0$. Then:
\begin{align*}
||\btau|| \leq C_D (||\text{dev}( \btau) ||+ || \text{div} (\btau) ||) \qquad \forall \btau \in H_N(\text{div},\Omega)^d
\end{align*}
Since the following inequalities hold:
\begin{align*}
 ||\text{dev}( \btau) ||\leq 2 \mu  || \mathcal{A}\btau || \qquad   ||\text{dev}( \btau) ||\leq \sqrt{2 \mu}  (\mathcal{A}\btau,\btau)  \qquad \forall \btau \in H_N(\text{div},\Omega)^d
\end{align*}
We can also write:
\begin{align*}
||\btau|| \leq \hat{C}_D (|| \mathcal{A}\btau ||+ || \text{div} (\btau) ||) \qquad  ||\btau|| \leq \tilde{C}_D ( (\mathcal{A}\btau,\btau) + || \text{div} (\btau) ||)  \qquad \forall \btau \in H_N(\text{div},\Omega)^d
\end{align*}




\section{The augmented functional is convex}
Let us consider
\begin{align*}
\mathcal{F}(\bu,\bsigma)=&\mathcal{F}_1(\bu,\bsigma)+\mathcal{F}_2(\bu,\bsigma)+\mathcal{F}_3(\bu,\bsigma)=\\
=&||\text{div} \bsigma+\bff||^2+||\mathcal{A}\bsigma -\boldsymbol{\varepsilon}(\bu)||^2+\langle \bu \cdot \bn-g, (\bsigma \bn) \cdot \bn \rangle_{\Gamma_C} 
\end{align*}
whose derivative is the combination of:
\begin{align*}
\mathcal{F}_1(\bu,\bsigma)' \left[ \bu_h, \bsigma_h \right]&= 2 \left( \text{div} \bsigma + \bff,  \text{div} \bsigma_h \right)\\
\mathcal{F}_2(\bu,\bsigma)' \left[ \bu_h, \bsigma_h \right]&=2 \left( \mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu),\mathcal{A} \bsigma_h - \boldsymbol{\varepsilon} (\bu_h) \right)\\
\mathcal{F}_3(\bu,\bsigma)' \left[ \bu_h, \bsigma_h \right]&=\langle \bu_h \cdot \bn-g, (\bsigma \bn) \cdot \bn \rangle_{\Gamma_C} +\langle \bu \cdot \bn-g, (\bsigma_h \bn) \cdot \bn \rangle_{\Gamma_C}
\end{align*}
so that:
\begin{align*}
\mathcal{F}(\bu,\bsigma)' \left[ \bu_h, \bsigma_h \right]=& 2 \left( \text{div} \bsigma + \bff,  \text{div} \bsigma_h \right)+
2 \left( \mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu),\mathcal{A} \bsigma_h - \boldsymbol{\varepsilon} (\bu_h) \right)+\\
&\langle \bu_h \cdot \bn-g, (\bsigma \bn) \cdot \bn \rangle_{\Gamma_C} +\langle \bu \cdot \bn-g, (\bsigma_h \bn) \cdot \bn \rangle_{\Gamma_C}
\end{align*}
We can show that the functional $\mathcal{F}$ is convex by means of the equivalent statement:
\begin{align*}
\mathcal{F}(\bu +\bu_h,\bsigma+\bsigma_h) -\mathcal{F}(\bu_h,\bsigma) \geq \mathcal{F}(\bu,\bsigma)' \left[ \bu_h, \bsigma_h \right]
\end{align*}
In particular we have:
\begin{align*}
\mathcal{F}_1(\bu,\bsigma)' \left[ \bu_h, \bsigma_h \right] \leq & 
2 \left( \text{div} \bsigma + \bff,  \text{div} \bsigma_h \right)+\left( \text{div} \bsigma_h \,  \text{div} \bsigma_h \right)\\
\mathcal{F}_2(\bu,\bsigma)' \left[ \bu_h, \bsigma_h \right] \leq & 
2 \left( \mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu),\mathcal{A} \bsigma_h - \boldsymbol{\varepsilon} (\bu_h) \right)+
\left( \mathcal{A} \bsigma_h - \boldsymbol{\varepsilon} (\bu_h),\mathcal{A} \bsigma_h - \boldsymbol{\varepsilon} (\bu_h) \right) \\
\mathcal{F}_3(\bu,\bsigma)' \left[ \bu_h, \bsigma_h \right] \leq 
& \langle \bu_h \cdot \bn-g, (\bsigma \bn) \cdot \bn \rangle_{\Gamma_C} +\langle \bu \cdot \bn-g, (\bsigma_h \bn) \cdot \bn \rangle_{\Gamma_C}+\langle \bu_h \cdot \bn-g, (\bsigma_h \bn) \cdot \bn \rangle_{\Gamma_C}
\end{align*}

where the last inequality holds thanks to the constraints. The gradient of the functional is:
\begin{align*}
\dfrac{\partial  \mathcal{F}(\bu,\bsigma)}{\partial \bu } \left[ \bu_h \right]=& 
-2 \left( \mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu), \boldsymbol{\varepsilon} (\bu_h ) \right)+\langle \bn \cdot \bu_h,  (\bsigma \bn) \cdot \bn \rangle_{\Gamma_C}\\
\dfrac{\partial  \mathcal{F}(\bu,\bsigma)}{\partial \bsigma } \left[ \bsigma_h \right]=& 
2 \left( \text{div} \bsigma + \bff,  \text{div} \bsigma_h \right)
+2 \left( \mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu), \mathcal{A} \bsigma_h \right)
+\langle \bu \cdot \bn-g, ( \bsigma_h \: \bn) \cdot \bn \rangle_{\Gamma_C}
\end{align*}
In order to obtain the normal equations, we need some adjoints operators (DUBBIO: SU GAMMAC HO OPERATORI DI TRACCIA):
\begin{align*}
\left( \mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu), \boldsymbol{\varepsilon} (\bu_h ) \right)&=\int_{\Omega} (\mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu)) : \boldsymbol{\varepsilon} (\bu_h )=
\int_{\Omega} (\mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu)) : \frac{1}{2} \left( \nabla \bu_h+ \nabla^T \bu_h \right) \\
&=\int_{\Omega} (\mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu)) : \frac{1}{2}  \nabla \bu_h + \int_{\Omega} (\mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu))^T : \frac{1}{2}  \nabla \bu_h \\
&=\int_{\Omega} (\mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu)) :  \nabla \bu_h \\
&=\int_{ \Gamma_d} (\mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu))  \bn \cdot \bu_h -\int_{\Omega} \text{div} \left(\mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu) \right)\cdot \bu_h \ \\
\\ 
\langle \bn \bu_h,  (\bsigma \bn) \cdot \bn \rangle_{\Gamma_C}&=\int_{\Gamma_C}   (\bu_h \cdot \bn )  \left[(\bsigma \bn) \cdot \bn \right] = \int_{\Gamma_C}  (\bu_h \cdot \bn ) \bn  \cdot (\bsigma \bn) \\
\left( \text{div} \bsigma + \bff,  \text{div} \bsigma_h \right)&= \int_{\Omega} ( \text{div} \bsigma + \bff) \text{div} \bsigma_h =\int_{\Gamma_N}  ( \text{div} \bsigma + \bff) \cdot  \bsigma_h \bn -\int_{\Omega} \nabla( \text{div} \bsigma + \bff) : \bsigma_h \\
 \left( \mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu), \mathcal{A} \bsigma_h \right)&=
 \int_{\Omega}\left(\mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu)\right): \mathcal{A} \bsigma_h\\
 &=\int_{\Omega}\left(\mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu)\right) : \left(\dfrac{1}{2 \mu} \bsigma_h- \dfrac{\lambda}{d \lambda + 2 \mu} \text{tr} \bsigma_h \bI \right)\\
  &=\int_{\Omega}\dfrac{1}{2 \mu} \left(\mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu)\right)  : \bsigma_h- \dfrac{\lambda}{d \lambda + 2 \mu} \text{tr}\left( \mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu)\right)   \bI :\bsigma_h\\
   &=\int_{\Omega} \left[ \dfrac{1}{2 \mu} \left(\mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu)\right)  - \dfrac{\lambda}{d \lambda + 2 \mu} \text{tr}\left( \mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu)\right)   \bI \right] :\bsigma_h\\
      &=\int_{\Omega} \left[ \mathcal{A}\left(\mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu)\right) \right] :\bsigma_h\\
 \\
\langle \bn \cdot \bu-g,  (\bsigma_h \bn) \cdot \bn \rangle_{\Gamma_C}&=\int_{\Gamma_C}   (\bu \cdot \bn -g )  \left[(\bsigma_h \bn) \cdot \bn \right] = \int_{\Gamma_C}  (\bu \cdot \bn -g ) \bn  \cdot (\bsigma_h \bn) \\
\end{align*}
So that:
\begin{align*}
\dfrac{\partial  \mathcal{F}(\bu,\bsigma)}{\partial \bu } \left[ \bu_h \right]=& 
-2 \int_{ \Gamma_d} (\mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu))  \bn \cdot \bu_h -2 \int_{\Omega} \text{div} \left(\mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu) \right)\cdot \bu_h \\
&+\int_{\Gamma_C}  (\bu_h \cdot \bn ) \bn  \cdot (\bsigma \bn) 
\\
\dfrac{\partial  \mathcal{F}(\bu,\bsigma)}{\partial \bsigma } \left[ \bsigma_h \right]=& 
+2\int_{\Gamma_N}  ( \text{div} \bsigma + \bff) \cdot  \bsigma_h \bn -2 \int_{\Omega} \nabla( \text{div} \bsigma + \bff) : \bsigma_h\\
&+2\int_{\Omega} \left[ \mathcal{A}\left(\mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu)\right) \right] :\bsigma_h\\
&+\int_{\Gamma_C}  (\bu \cdot \bn -g ) \bn  \cdot (\bsigma_h \bn) \
\end{align*}
The operator equation associated to the residual energy functional is:
\begin{align*}
\text{div} \left(\mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu) \right)= \textbf{0}\\
- \nabla( \text{div} \bsigma + \bff) +\left[ \mathcal{A}\left(\mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu)\right) \right] = \textbf{0}\\
\end{align*}
DOMANDA: ottengo un problema del tipo Ax=b. La matrice dovrebbe essere non singolare, quindi dovrebbe esistere una unica soluzione. Ora, i vincoli del problema di contatto, dove rientrano in tutto questo?\\\\
A ME NON SEMBRA PUNTO SELLA. Tuttavia se moltiplico la prima per divTAU, la seconda per v, potrei ritrovare una sorta di punto sella ponendo Asigma-eps=C .MMM \\\\
In the first equation, the term on $\Gamma_d$ is zero due to the test function.\\
L'INTEGRALE SU GAMMAC non capisco perche si annulli.\\
Being $\Gamma_C \subset \Gamma_N$ and $\bsigma \bn =$ on $\Gamma_N$ the boundary integrals of the second equation vanish.
\section{Discretization}
\begin{align*}
\dfrac{\partial  \mathcal{F}(\bu,\bsigma)}{\partial \bu } \left[ \bu_h \right]=& 
-2 \left( \mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu), \boldsymbol{\varepsilon} (\bu_h ) \right)+\langle \bn \cdot \bu_h,  (\bsigma \bn) \cdot \bn \rangle_{\Gamma_C} =0 \\
\dfrac{\partial  \mathcal{F}(\bu,\bsigma)}{\partial \bsigma } \left[ \bsigma_h \right]=& 
2 \left( \text{div} \bsigma + \bff,  \text{div} \bsigma_h \right)
+2 \left( \mathcal{A} \bsigma - \boldsymbol{\varepsilon} (\bu), \mathcal{A} \bsigma_h \right)
+\langle \bu \cdot \bn-g, ( \bsigma_h \: \bn) \cdot \bn \rangle_{\Gamma_C} =0
\end{align*}
Let be:
\begin{align*}
\bsigma = \sum_{j=1}^{N_{\sigma}} \sigma_i \bphi_i \qquad \bu= \sum_{n=1}^{N_{\bu}} u_j \bpsi_j \qquad \bsigma_h = \bphi_i \qquad \bu_h= \bpsi_m
\end{align*}
Then:
\begin{align*}
& B_{1,\:ij}= -\int_{\Omega}  \mathcal{A} \bphi_i : \beps (\bpsi_j) & B_1 \in \mathcal{R}^{N_u \times N_{\sigma}}\\ 
& B_{2,\:ij}= \int_{\Omega}  \beps (\bphi_i) : \beps (\bpsi_j) & B_2 \in \mathcal{R}^{N_u \times N_{u}}\\ 
& B_{3,\:ij}= \frac{1}{2} \int_{\Gamma_c}   (\bphi_i \bn) \cdot \bn  (\bn \cdot \bpsi_j)  &B_3 \in \mathcal{R}^{N_u \times N_{\sigma}}\\ 
& B_{4,\:ij}=  \int_{\Omega}  \text{div} \bphi_i \cdot \text{div} \bphi_j  &B_4 \in \mathcal{R}^{N_{\sigma} \times N_{\sigma}}\\ 
& B_{5,\:ij}=  \int_{\Omega}  \mathcal{A} \bphi_i : \mathcal{A} \bphi_j  &B_5 \in \mathcal{R}^{N_{\sigma} \times N_{\sigma}}\\ 
&F_{1,\:ij}=\frac{1}{2} \int_{\Gamma_c}g \:(\bphi_j \bn)\cdot \bn& F_1 \in \mathcal{R}^{N_{\sigma} }\\ 
&F_{2,\:ij}=- \int_{\Omega} \bff \cdot \text{div} \bphi_j & F_2 \in \mathcal{R}^{N_{\sigma} }\\ 
\end{align*}
and (+ constraints??????):
\begin{align*}
\begin{bmatrix}
B_1^T+B_3^T &B_4 + B_5\\
B_2  & B_1+B_3
\end{bmatrix}
\begin{bmatrix}
\bu\\
\bsigma
\end{bmatrix}
=
\begin{bmatrix}
F_1+F2\\
0
\end{bmatrix}
\end{align*}
Substituting:

\begin{align*}
\begin{cases}
\bu= - B_2^{-1}(B_1+B_3) \bsigma\\
-(B_1+B_3)^T B_2^{-1}(B_1+B_3) \bsigma + (B_4+B_5) \bsigma = F_1+F_2\\
C= B_1+B_3\\
D=B_4+B_5
\end{cases}
\quad \to \quad
\begin{cases}
\bsigma= \left( -C^T B_2^{-1} C + D \right)^{-1} (F_1+F_2)\\
\bu= - B_2^{-1}(B_1+B_3) \bsigma
\end{cases}
\end{align*}

\section{Raviart Thomas}
Computation of the divergence in 2D:
\begin{align*}
\text{div}_{\bbx} \bphi(\bbx)&= \text{div}_{\bbx} \left[ \dfrac{1}{\text{detJ}} \bJ\hat{\bphi}(F^{-1}(\bbx)) \right]\\
&=\dfrac{1}{\text{detJ}}  \left[ \dfrac{d}{dx}\left( J_{11} \hat{\phi}_1(\hat{\bbx}) +J_{12} \hat{\phi}_2(\hat{\bbx}) \right)
+\dfrac{d}{dy}
\left(  J_{21} \hat{\phi}_1(\hat{\bbx}) +J_{22} \hat{\phi}_2(\hat{\bbx})\right)
\right]\\
&=\dfrac{1}{\text{detJ}}  \bigg [
 \dfrac{\partial}{\partial \xi}\left( J_{11} \hat{\phi}_1(\hat{\bbx}) +J_{12} \hat{\phi}_2(\hat{\bbx}) \right) \dfrac{d \xi}{dx}+
\dfrac{\partial}{\partial \eta}\left( J_{11} \hat{\phi}_1(\hat{\bbx}) +J_{12} \hat{\phi}_2(\hat{\bbx}) \right) \dfrac{d \eta}{dx} \\
&+\dfrac{\partial}{\partial \xi}
\left(  J_{21} \hat{\phi}_1(\hat{\bbx}) +J_{22} \hat{\phi}_2(\hat{\bbx})\right) \dfrac{d \xi }{dy}
+\dfrac{\partial}{\partial \eta}
\left(  J_{21} \hat{\phi}_1(\hat{\bbx}) +J_{22} \hat{\phi}_2(\hat{\bbx})\right) \dfrac{d \eta }{dy}
\bigg ]
\end{align*}
The shape functions are:
\begin{align*}
\hat{\bphi}_a(\xi,\eta) =\begin{bmatrix}
\xi \\
\eta -1
\end{bmatrix}
\qquad
\hat{\bphi}_b(\xi,\eta) =\begin{bmatrix}
\xi \\
\eta 
\end{bmatrix}
\qquad
\hat{\bphi}_c(\xi,\eta) =\begin{bmatrix}
1-\xi \\
-\eta
\end{bmatrix}
\end{align*}
Using:
\begin{align*}
&\dfrac{\partial \phi_{a,1} }{\partial \xi}= 1 \qquad 
\dfrac{\partial \phi_{a,1} }{\partial \eta}= 0 \qquad 
\dfrac{\partial \phi_{a,2} }{\partial \xi}= 0 \qquad 
\dfrac{\partial \phi_{a,2} }{\partial \eta}= 1 \qquad \\
&\dfrac{\partial \phi_{b,1} }{\partial \xi}= 1 \qquad 
\dfrac{\partial \phi_{b,1} }{\partial \eta}= 0 \qquad 
\dfrac{\partial \phi_{b,2} }{\partial \xi}= 0 \qquad 
\dfrac{\partial \phi_{b,2} }{\partial \eta}= 1 \qquad \\
&\dfrac{\partial \phi_{c,1} }{\partial \xi}= - 1 \qquad 
\dfrac{\partial \phi_{c,1} }{\partial \eta}= 0 \qquad 
\dfrac{\partial \phi_{c,2} }{\partial \xi}= 0 \qquad 
\dfrac{\partial \phi_{c,2} }{\partial \eta}= -1 \qquad \\
\end{align*}
We obtain:
\begin{align*}
\text{div}_{\bbx} \bphi_a(\bbx)
&=\dfrac{1}{\text{detJ}}  \bigg [
 +J_{11}  \dfrac{d \xi}{dx} +J_{12}\dfrac{d \eta}{dx} +
  J_{21}\dfrac{d \xi }{dy}
+ J_{22}  \dfrac{d \eta }{dy}
\bigg ]\\
\text{div}_{\bbx} \bphi_b(\bbx)
&=\dfrac{1}{\text{detJ}}  \bigg [
 +J_{11}  \dfrac{d \xi}{dx} +J_{12}\dfrac{d \eta}{dx} +
  J_{21}\dfrac{d \xi }{dy}
+ J_{22}  \dfrac{d \eta }{dy}
\bigg ]\\
\text{div}_{\bbx} \bphi_c(\bbx)
&=\dfrac{1}{\text{detJ}}  \bigg [
 -J_{11}  \dfrac{d \xi}{dx} -
 J_{12}\dfrac{d \eta}{dx} -
  J_{21}\dfrac{d \xi }{dy}
-J_{22}  \dfrac{d \eta }{dy}
\bigg ]\\
\end{align*}
We know that:
\begin{align*}
J^{-1}=\begin{bmatrix}
\dfrac{\partial \xi}{\partial x} &\dfrac{\partial \xi}{\partial y} \\
\dfrac{\partial \eta}{\partial x} &\dfrac{\partial \eta}{\partial y} \\
\end{bmatrix}=\dfrac{1}{\text{det J}}
\begin{bmatrix}
J_{22} & -J_{12}\\
-J_{21} & J_{11}
\end{bmatrix}
\end{align*}
So that:
\begin{align*}
\text{div}_{\bbx} \bphi_a(\bbx)
&=\dfrac{1}{\text{detJ}^2}  
\bigg [
 +J_{11} J_{22} -J_{12}J_{21} -
  J_{21}J_{12}
+ J_{22}  J_{11}
\bigg ]\\
&=\dfrac{1}{\text{detJ}^2}  
\bigg [
 +2 J_{11} J_{22} -2 J_{12}J_{21} 
\bigg ]\\
&=\dfrac{1}{\text{detJ}^2}  (2 \text{detJ})\\
&=2 \dfrac{1}{\text{detJ}}  \\
\text{div}_{\bbx} \bphi_b(\bbx)
&=\dfrac{1}{\text{detJ}^2}  \bigg [
 +J_{11}  J_{22} -J_{12}J_{21} -
  J_{21}J_{12}
+ J_{22}  J_{11}
\bigg ]\\
&=\dfrac{1}{\text{detJ}^2}  \bigg [
 + 2J_{11}  J_{22} -2 J_{12}J_{21}
\bigg ]\\
&=\dfrac{1}{\text{detJ}^2}  (2 \text{detJ})\\
&=2 \dfrac{1}{\text{detJ}}  \\
\text{div}_{\bbx} \bphi_c(\bbx)
&=\dfrac{1}{\text{detJ}^2}  \bigg [
 -J_{11}  J_{22} -J_{12}J_{21} +
  J_{21}J_{12}
+ J_{22}  J_{11}
\bigg ]\\
&=\dfrac{1}{\text{detJ}^2}  \bigg [
 - 2J_{11}  J_{22}+2 J_{12}J_{21}
\bigg ]\\
&=\dfrac{1}{\text{detJ}^2}  (-2 \text{detJ})\\
&=-2 \dfrac{1}{\text{detJ}}  
\end{align*}








Computation of the divergence in 3D:
\begin{align*}
\text{div}_{\bbx} \bphi(\bbx)=& \text{div}_{\bbx} \left[ \dfrac{1}{\text{detJ}} \bJ\hat{\bphi}(F^{-1}(\bbx)) \right]\\
=\dfrac{1}{\text{detJ}}  &
\bigg [
 \dfrac{d}{dx}
 \underbrace{\left( J_{11} \hat{\phi}_1(\hat{\bbx}) +J_{12} \hat{\phi}_2(\hat{\bbx})  + J_{13} \hat{\phi}_3(\hat{\bbx})\right)}_{F_1}\\
&+\dfrac{d}{dy}
 \underbrace{\left(  J_{21} \hat{\phi}_1(\hat{\bbx}) +J_{22} \hat{\phi}_2(\hat{\bbx})
+ J_{23} \hat{\phi}_3(\hat{\bbx}) \right)}_{F_2}\\
&+\dfrac{d}{dz}
 \underbrace{\left(  J_{31} \hat{\phi}_1(\hat{\bbx}) +J_{32} \hat{\phi}_2(\hat{\bbx})
+ J_{33} \hat{\phi}_3(\hat{\bbx}) \right)}_{F_3}
\bigg ]\\
&=\dfrac{1}{\text{detJ}}  \bigg [
 \dfrac{\partial F_1}{\partial \xi} \dfrac{d \xi}{dx}+
\dfrac{\partial F_1}{\partial \eta} \dfrac{d \eta}{dx}+\dfrac{\partial F_1}{\partial \zeta} \dfrac{d \zeta}{dz}+ \\
&+\dfrac{\partial F_2}{\partial \xi} \dfrac{d \xi }{dy}
+\dfrac{\partial F_2}{\partial \eta} \dfrac{d \eta }{dy}
+\dfrac{\partial F_2}{\partial \zeta} \dfrac{d \zeta}{dz}\\
&+\dfrac{\partial F_3}{\partial \xi} \dfrac{d \xi }{dy}
+\dfrac{\partial F_3}{\partial \eta} \dfrac{d \eta }{dy}
+\dfrac{\partial F_3 }{\partial \zeta} \dfrac{d \zeta}{dz}
\bigg ]
\end{align*}
The shape functions are:
\begin{align*}
\hat{\bphi}_a(\xi,\eta,\zeta) =\begin{bmatrix}
-\xi \\
-\eta\\
1-\zeta
\end{bmatrix}
\qquad
\hat{\bphi}_b(\xi,\eta,\zeta) =\begin{bmatrix}
\xi \\
\eta -1\\
\zeta
\end{bmatrix}
\qquad
\hat{\bphi}_c(\xi,\eta,\zeta) =\begin{bmatrix}
1-\xi \\
-\eta\\
-\zeta
\end{bmatrix}
\qquad
\hat{\bphi}_d(\xi,\eta,\zeta) =\begin{bmatrix}
\xi \\
\eta\\
\zeta
\end{bmatrix}
\end{align*}
So we have:
\begin{itemize}
\item for $\hat{\bphi}_a(\xi,\eta,\zeta)$
\begin{align*}
&\dfrac{\partial F_1 }{\partial \xi}=-J_{11}  \qquad 
\dfrac{\partial F_1 }{\partial \eta}= -J_{12} \qquad 
\dfrac{\partial F_1 }{\partial \zeta}= -J_{13} \\ 
&\dfrac{\partial F_2 }{\partial \xi}= -J_{21} \qquad 
\dfrac{\partial F_2 }{\partial \eta}= -J_{22}  \qquad 
\dfrac{\partial F_2 }{\partial \zeta}= -J_{23}  \\ 
&\dfrac{\partial F_3 }{\partial \xi}= -J_{31}  \qquad 
\dfrac{\partial F_3 }{\partial \eta}= -J_{32}  \qquad 
\dfrac{\partial F_3 }{\partial \zeta}= -J_{33}  \\ 
\end{align*}
\item for $\hat{\bphi}_b(\xi,\eta,\zeta)$
\begin{align*}
&\dfrac{\partial F_1 }{\partial \xi}=J_{11}  \qquad 
\dfrac{\partial F_1 }{\partial \eta}= J_{12} \qquad 
\dfrac{\partial F_1 }{\partial \zeta}= J_{13} \\ 
&\dfrac{\partial F_2 }{\partial \xi}= J_{21} \qquad 
\dfrac{\partial F_2 }{\partial \eta}= J_{22}  \qquad 
\dfrac{\partial F_2 }{\partial \zeta}= J_{23}  \\ 
&\dfrac{\partial F_3 }{\partial \xi}= J_{31}  \qquad 
\dfrac{\partial F_3 }{\partial \eta}= J_{32}  \qquad 
\dfrac{\partial F_3 }{\partial \zeta}=J_{33}  \\ 
\end{align*}
\item for $\hat{\bphi}_c(\xi,\eta,\zeta)$
\begin{align*}
&\dfrac{\partial F_1 }{\partial \xi}=-J_{11}  \qquad 
\dfrac{\partial F_1 }{\partial \eta}= -J_{12} \qquad 
\dfrac{\partial F_1 }{\partial \zeta}= -J_{13} \\ 
&\dfrac{\partial F_2 }{\partial \xi}= -J_{21} \qquad 
\dfrac{\partial F_2 }{\partial \eta}= -J_{22}  \qquad 
\dfrac{\partial F_2 }{\partial \zeta}= -J_{23}  \\ 
&\dfrac{\partial F_3 }{\partial \xi}= -J_{31}  \qquad 
\dfrac{\partial F_3 }{\partial \eta}= -J_{32}  \qquad 
\dfrac{\partial F_3 }{\partial \zeta}= -J_{33}  \\ 
\end{align*}
\item for $\hat{\bphi}_d(\xi,\eta,\zeta)$
\begin{align*}
&\dfrac{\partial F_1 }{\partial \xi}=J_{11}  \qquad 
\dfrac{\partial F_1 }{\partial \eta}= J_{12} \qquad 
\dfrac{\partial F_1 }{\partial \zeta}= J_{13} \\ 
&\dfrac{\partial F_2 }{\partial \xi}= J_{21} \qquad 
\dfrac{\partial F_2 }{\partial \eta}= J_{22}  \qquad 
\dfrac{\partial F_2 }{\partial \zeta}= J_{23}  \\ 
&\dfrac{\partial F_3 }{\partial \xi}= J_{31}  \qquad 
\dfrac{\partial F_3 }{\partial \eta}= J_{32}  \qquad 
\dfrac{\partial F_3 }{\partial \zeta}=J_{33}  \\ 
\end{align*}
\end{itemize}

So:
\begin{align*}
\text{div}_{\bbx} \bphi_{a,b,c,d}(\bbx)&=\pm \dfrac{1}{\text{detJ}}    \bJ : \bJ^{-T}
\end{align*}


We obtain:
\begin{align*}
\text{div}_{\bbx} \bphi_a(\bbx)
&=\dfrac{1}{\text{detJ}}  \bigg [
 +J_{11}  \dfrac{d \xi}{dx} +J_{12}\dfrac{d \eta}{dx} +
  J_{21}\dfrac{d \xi }{dy}
+ J_{22}  \dfrac{d \eta }{dy}
\bigg ]\\
\text{div}_{\bbx} \bphi_b(\bbx)
&=\dfrac{1}{\text{detJ}}  \bigg [
 +J_{11}  \dfrac{d \xi}{dx} +J_{12}\dfrac{d \eta}{dx} +
  J_{21}\dfrac{d \xi }{dy}
+ J_{22}  \dfrac{d \eta }{dy}
\bigg ]\\
\text{div}_{\bbx} \bphi_c(\bbx)
&=\dfrac{1}{\text{detJ}}  \bigg [
 -J_{11}  \dfrac{d \xi}{dx} -
 J_{12}\dfrac{d \eta}{dx} -
  J_{21}\dfrac{d \xi }{dy}
-J_{22}  \dfrac{d \eta }{dy}
\bigg ]\\
\end{align*}
We know that:
\begin{align*}
J^{-1}=\begin{bmatrix}
\dfrac{\partial \xi}{\partial x} &\dfrac{\partial \xi}{\partial y}  & \dfrac{\partial \xi}{\partial z} \\
\dfrac{\partial \eta}{\partial x} &\dfrac{\partial \eta}{\partial y} &\dfrac{\partial \eta}{\partial z} \\
\dfrac{\partial \zeta}{\partial x} &\dfrac{\partial \zeta}{\partial y} &\dfrac{\partial \zeta}{\partial z} \\
\end{bmatrix}=\dfrac{1}{\text{det J}}
\begin{bmatrix}
J_{22} J_{33}- J_{23} J_{32}&
 J_{13} J_{32} - J_{12}J_{33}&
 J_{12}J_{23}-J_{13}J_{22}\\
 J_{23} J_{31}- J_{21} J_{33}&
 J_{11} J_{33} - J_{13}J_{31}&
 J_{13}J_{21}-J_{11}J_{23}\\
 J_{21} J_{32}- J_{22} J_{31}&
 J_{12} J_{31} - J_{11}J_{32}&
 J_{11}J_{22}-J_{12}J_{21}\\
\end{bmatrix}
\end{align*}
So that:
\begin{align*}
\begin{cases}
\text{div}_{\bbx} \bphi(\bbx)=\alpha \dfrac{3}{\text{detJ}}  \\
\alpha =\begin{cases}
+1 \qquad \text{outward normal}\\
-1 \qquad \text{inward normal}\\
\end{cases}
\end{cases}
\end{align*}
For a generic dimension $d=2,3$:
\begin{align*}
\begin{cases}
\text{div}_{\bbx} \bphi(\bbx)=\alpha \dfrac{d}{\text{detJ}}  \\
d=\text{dimension}\\
\alpha =\begin{cases}
+1 \qquad \text{outward normal}\\
-1 \qquad \text{inward normal}\\
\end{cases}
\end{cases}
\end{align*}

\section{Mass Matrix}
Given the reference shape functions:
\begin{align*}
\hat{\bphi}_a(\xi,\eta) =\begin{bmatrix}
\xi \\
\eta -1
\end{bmatrix}
\qquad
\hat{\bphi}_b(\xi,\eta) =\begin{bmatrix}
\xi \\
\eta 
\end{bmatrix}
\qquad
\hat{\bphi}_c(\xi,\eta) =\begin{bmatrix}
1-\xi \\
-\eta
\end{bmatrix}
\end{align*}
We want to compute the reference mass matrix:
\begin{align*}
M_{loc}=\int_{\hat{K}} \hat{\bphi}_i(\xi,\eta) \cdot \hat{\bphi}_j(\xi,\eta) d\hat{K} \qquad i,\:j=a,b,c
\end{align*}
The result is:
\begin{align*}
M_{loc}=
\begin{bmatrix}
\frac{1}{3} & 0 & \frac{1}{6}\\
0 & \frac{1}{6} & 0\\
\frac{1}{6} & 0 & \frac{1}{3}
\end{bmatrix}
\end{align*}
In general we want to compute:
\begin{align*}
M=\int_{{K}} {\bphi}_i(x,y) \cdot{\bphi}_j(x,y) {K} =\dfrac{1}{\text{det}J}
\int_{\hat{K}} (\bJ \hat{\bphi}_i(\xi,\eta))\cdot (\bJ \hat{\bphi}_j(\xi,\eta)) d\hat{K}=\int_{\hat{K}} \psi(\bJ, \xi,\eta,i,j) d\hat{K}
\qquad i,\:j=a,b,c
\end{align*}
where:
\begin{align*}
 \psi(\bJ, \xi,\eta,i,j) =
c_{xx} \hat{\bphi}_{i,x}\hat{\bphi}_{j,x} +
c_{yy} \hat{\bphi}_{i,y}\hat{\bphi}_{j,y} +
c_{xy}(\hat{\bphi}_{i,x}\hat{\bphi}_{j,y} +\hat{\bphi}_{i,y}\hat{\bphi}_{j,x} )\\
c_{xx} =(J_{11}^2+J_{21}^2) \qquad 
c_{yy} =(J_{12}^2+J_{22}^2) \qquad
c_{xy} =(J_{12} J_{11} + J_{21} J_{22}) 
\end{align*}
If we define:
\begin{align*}
a_1= \frac{1}{12|\text{det}|}  \qquad a_2=\frac{1}{4|\text{det}| }
\end{align*}


    
\begin{center}
  \begin{tabular}{ | l |c| c | r | }
    \hline
(i,j) &            & &      \\ \hline
(1,1)&    $a_1$ & $a_2$ &  $-a_2$  \\ \hline
(1,2)&    $a_1$ & $-a_1$ &$-a_1$\\ \hline
(1,3)&    $a_1$ & $a_1$ &$- a_2 $\\ \hline
(2,2)&    $a_1$ & $a_1$ & $a_1 $\\ \hline
(2,3)&    $a_1$ & $-a_1$ &$a_1 $\\ \hline
(3,3)&    $a_2$ & $a_1$ & $-a_2$ \\
    \hline
  \end{tabular}
\end{center}

For the computation of a mixed term ($\phi_j$ shape function for the displacement):
\begin{align*}
\int_{{K}} \text{div}{\bphi}_i(x,y) {\phi}_j(x,y) d{K} =
|\text{det}J| \int_{\hat{K}} \alpha \: \dfrac{\text{dim}}{\text{det}J} \: {\phi}_j(\xi,\eta) d \hat{K} =
\alpha \: \text{dim} \: \text{sign}J \int_{\hat{K}}  {\phi}_j(\xi,\eta) d \hat{K} 
\end{align*}

\section{Essential Boundary Condition}
Neumann conditions become essential in the Raviart-Thomas framework:
\begin{align*}
\bu \cdot \bn = f \qquad \Gamma_N
\end{align*}
Substituing $\bu = \sum_{i=1}^N U_i \bphi_i(x,y)$ and taking advantage of the support of each shape function, we obtain that on the boundayr:
\begin{align*}
\sum_{i=1}^N U_i \bphi_i(x,y) \cdot \bn =  U_i \bphi_i(x,y) \cdot \bn =  U_i  \alpha \dfrac{1}{L} = f \qquad \Gamma_N
\end{align*}
\begin{align*}
\begin{cases}
 U_i  \:\alpha \:\frac{1}{L} = f \qquad \Gamma_N\\
 \alpha=\begin{cases}
 +1 \qquad \text{outward Raviart-Thomas's normal}\\
 -1 \qquad \text{inward Raviart-Thomas's normal}
 \end{cases}\\
 L= \text{length of the side of the triangle}
 \end{cases}
\end{align*}
So that:
\begin{align*}
 U_i  -\alpha \: L \: f=0 \qquad \forall i \: \text{on} \: \Gamma_N
\end{align*}
\end{document}  